[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Content\n\nIntroduction\nWeek1\nWeek2\nWeek3\nWeek4\nWeek5\nWeek6\nWeek7\nWeek8\nWeek9"
  },
  {
    "objectID": "Week2.html",
    "href": "Week2.html",
    "title": "2  Week 2 Portfolio",
    "section": "",
    "text": "In this week, we learnt making slides by Xaringan in Rstudio and writing learning diary by Quarto as well. I made a Xaringan slides for summarizing Landsat 8 OLI sensor, and collected several applications based on OLI imagery. Following url is my Xaringan slides link. I think that after this exercise I will be able to master the basic usage of Xaringan to create slideshows and be able to use Xaringan proficiently.\nMy week2 Xaringan presentation link is: Week2 Xaringan Presentation slide (https://luzhao2000.github.io/RS_week2_pre/)"
  },
  {
    "objectID": "intro.html#background",
    "href": "intro.html#background",
    "title": "1  Introduction",
    "section": "1.1 Background",
    "text": "1.1 Background\nHello everyone, my name is Lu, and I am a CASA Masters student enrolled in September 2022 and will graduate in September 2023. My course is Urban Spatial Science, which is an interdisciplinary specialisation in GIS, remote sensing, quantitative analysis, data science, agent-based modelling, and theories related to smart cities.\nI chose this course because I am very interested in satellites and remote sensing images. I can see through these images the long stretches of mountains and the endless sea, which are the places that I might not otherwise go. I think the technology of remote sensing provides me with another way to understand and explore our planet."
  },
  {
    "objectID": "intro.html#education-experience",
    "href": "intro.html#education-experience",
    "title": "1  Introduction",
    "section": "1.2 Education experience",
    "text": "1.2 Education experience\nI attended Capital Normal University and the University of Waterloo for my undergraduate studies from 2018 to 2022. At Capital Normal University, I studied Remote Sensing Science and Technology, and in my courses, I was mainly involved in GIS, remote sensing, advanced mathematics, algebra, probability and statistics, and programming.\nI am very fortunate to be able to participate in the 2+2 externship program between Capital Normal University and the University of Waterloo in Canada. During my two years of study at the University of Waterloo, I majored in Geomatics with a focus on the application of GIS and remote sensing technology and the completion of projects, and I also minored in Mathematics.\nI am currently studying Urban Spatial Science at UCL."
  },
  {
    "objectID": "intro.html#professional-experience",
    "href": "intro.html#professional-experience",
    "title": "1  Introduction",
    "section": "1.3 Professional experience",
    "text": "1.3 Professional experience\nI have a relatively extensive professional experience.\nFirstly, during my undergraduate studies I was involved in 3S Field Investigation at Beijing Wild Duck Lake Wetland Nature Reserve, where I used spectral feature curve data and high-resolution remote sensing imagery from field surveys to perform supervised and unsupervised classification based on ENVI and object-oriented classification based on eCognit. The analysis of land use change was carried out using supervised classification based on ENVI, unsupervised classification and object-oriented classification based on eCognition.\nIn addition, I have worked on ArcGIS Pro and ENVI to analyzing the urban area ahanges from 1975 to 2010 in Toronto and Montreal, analyzing the factors that influence the unemployment rate in London from 2012 to 2021 based on Python, and geospatial weighted regression analysis and multi-factor regression analysis to analyse the factors influencing the spread of COVID-19 in Hubei Province, China by using ArcGIS."
  },
  {
    "objectID": "intro.html#interests",
    "href": "intro.html#interests",
    "title": "1  Introduction",
    "section": "1.4 Interests",
    "text": "1.4 Interests\nI have a relatively strong interest in smart cities and urban analytics. In my previous internship work I have learned about some examples of projects where smart cities were actually used, which made me very interested in digital, more scientifically planned and managed urban systems. At the same time, through the combination of large amounts of data computing and aspects such as GIS, cities can be managed more intelligently and efficiently.\nIn my spare time, I really enjoy reading books and travelling. I think reading allows me to understand and learn new knowledge and cultures more quickly, and to stay creative and imaginative. Travelling allows me to measure the world and open my eyes through my own feet, and is also a way to release stress. I also enjoy yoga and cycling, as proper exercise not only keeps me fit and healthy so that I can focus more when studying, but also relieves tension and heavy coursework."
  },
  {
    "objectID": "intro.html#hope-to-learn",
    "href": "intro.html#hope-to-learn",
    "title": "1  Introduction",
    "section": "1.5 Hope to learn",
    "text": "1.5 Hope to learn"
  },
  {
    "objectID": "Week5.html",
    "href": "Week5.html",
    "title": "Week 5 Google Earth Engine I",
    "section": "",
    "text": "Summary\nApplication\nReflection"
  },
  {
    "objectID": "intro.html#expectations",
    "href": "intro.html#expectations",
    "title": "1  Introduction",
    "section": "1.5 Expectations",
    "text": "1.5 Expectations\nBased on my ideas and my basic situation, I hope that through this course I will become more familiar with the knowledge related to remote sensing and be able to consolidate the theoretical knowledge with practical applications. In addition, I also would like to learn more about cutting-edge technologies and developments in this field as a way to expand my knowledge."
  },
  {
    "objectID": "Week4.html#summary",
    "href": "Week4.html#summary",
    "title": "4  Week 4 Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nUrban heat island is a worldwide phenomena, which happends more commonly in the metroplois and the city with high development speed, such as Guangzhou, Paris, and Toronto (Environment 2021). New York has the necessary pronounced seasonal urban heat island effect, which is more pronounced in the spring and fall (Gaffin et al. 2008). Prior to 2003, the urban heat island effect in New York might be attributed to the construction of skyscrapers in the Manhattan area and the expansion of the city (Gaffin et al. 2008).\nIn the policy “OneNYC 2050 BUILDING A STRONG AND FAIR CITY”, a series of policies have been proposed to address the effects of New York’s urban heat island effect in recent years, which not only exacerbates environmental warming, but also causes heat-related diseases (Fuleihan, Williams, and Zarrilli, n.d.). Therefore, it is necessary to mitigate the urban heat island effect in New York.\nIn order to mitigate the urban heat island effect and greenhouse gas emissions, the Cool Roof program was proposed in 2009 (“NYC CoolRoofs,” n.d.). The fundamental principle of mitigating the urban heat island effect relies on roofs coated with a special coating that has a high solar reflectivity and high infrared emissivity, reflecting the maximum amount of visible, infrared and ultraviolet light from the sun (“NYC CoolRoofs,” n.d.). However, cool roofs are currently only available through “Cool It Yourself” for installation on private properties, low-income, non-profit and citywide public institutions (“NYC CoolRoofs,” n.d.).\n\n\n\nFig.1 Distribution of cool roof project in New York City. Source: Fuleihan, Williams, and Zarrilli (n.d.)\n\n\nIn the two policies mentioned above, the use of cool roofs to mitigate the urban heat island effect in New York City has been proven to be a less costly and effective method of cooling the city. However, there are other ways to mitigate the urban heat island effect in practice.\nAccording to Jennifer et al. (n.d.), there are two common ways to mitigate the influence of urban heat island, one is increasing the reflectance of the surface of buildings to decrease the energy from the sun, the other is increasing the area of green space to decrease the evapotranspiration. In addition to this, Yamamoto (2006) also suggested that attempts could be made at the regional level to centralize the control of heat emission from buildings, the maintenance and improvement of parks and green spaces in the city, and the reorientation of industrial and commercial facilities according to the prevailing wind direction. Peng et al. (2020) found that the presence of water body could also help cool the city."
  },
  {
    "objectID": "Week4.html#application",
    "href": "Week4.html#application",
    "title": "4  Week 4 Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\n\nhow the remotely sensed data you sourced could be used to assist with contributing to the policy goal?\n\nBased on the above methods to mitigate the urban heat island effect, I found several suitable data sets and approaches which can be used to assist with contributing to the policy goals.\nWe need to compare the distribution of LST within New York City before the implementation of these measures and after the implementation to judge the effectiveness of the measures. If we want to mitigate the urban heat islands effect by adding cool roofs, or expanding green space in the city, or protecting water body can use Landsat 8 OLI/TIRS images to compute land surface temperature and classify different types of land use and land cover to identify the buildings, green space, water body, and other types of regions which are important to contribute the policy goal (Peng et al. 2020). Besides that, radiative transfer equation (RTE) can be used to calculate LST based on Landsat images by using ENVI (Peng et al. 2020). Besides that, the selection of areas with severe urban heat island effect can be made by combining Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) imagery containing evening thermal infrared data and Landsat 8 TIRS imagery containing daytime thermal infrared data, and judged by the results of Getis-Ord-Gi cluster analysis in ArcMAP (Mullerova and Williams 2019). However, Shaker et al. (2019) believe that the widely used LST does not accurately represent the temperature of building surfaces and other feature surfaces, so they chose to use free open-source data from weather stations combined with Landsat remote sensing imagery directly. Shaker et al. (2019) also chose to use LIDAR data to generate a Digital Elevation Model (DEM) to be generated as the study area’s input surface. In conclusion, using LIDAR data to generate DEM as the input surface, combining weather station data, Landsat 8 images and ASTER imagery to identify the distribution of UHI is a possible solution to assist with contributing to the policy goal, that is mitigate the urban heat island effect in New York City .\n\nHow could the data be applied to solve the policy challenge?\n\nAccording to the policy “OneNYC 2050 BUILDING A STRONG AND FAIR CITY” (n.d.), challenges in achieving the policy goals include limited funding, materials for the cool roofs, and what kind of buildings can have additional cool roofs. Firstly, the choice of reflective coating materials for cool roofs should meet the characteristics of environmental protection, long-term use and water resistance as much as possible. Secondly, the funds for roof addition are limited and cannot be completed for adding cool roofs for all buildings in New York City at once, so it might be possible that priority can be given to buildings with higher temperature and absorb more heat or buildings in densely populated areas. The method of selecting such buildings can be done by calculating the temperature of the land surface with the help of Landsat 8 TIRS images and selecting the target buildings for adding cool roofs (Mullerova and Williams 2019), and selecting the target buildings for roofing based on the population density data released by United States Census Bureau (Bureau, n.d.). This can solve the challenges encountered in the implementation of this policy to some extents.\nIn addition, according to the resolution of LST computed based on Landsat 8 images, it might not be suitable for analyzing the small-sized green space. Peng et al. (2020) suggested to use K-means cluster analysis to combine the small-sized green space into clusters."
  },
  {
    "objectID": "Week4.html#reflection",
    "href": "Week4.html#reflection",
    "title": "4  Week 4 Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\nwhat you have learnt in relation to the policy, city and the application of the data?\n\nThe urban heat island effect has a negative impact not only on the climate and nature, but also on humans, with an average of 87 deaths per year from heat-related diseases in New York as of 2011 (Jennifer et al., n.d.). This is why New York’s government and related agencies have proposed 219 policies to mitigate the urban heat island effect over a 10-year period (Jennifer et al., n.d.). This made me reflect not only on how to focus on the rapid development of cities, but also on the ability to take responsibility for dealing with the negative impacts of urban development, protecting the ecosystem, and protecting people, without losing sight of the other.\n\nWhat is interesting?\n\nThe policy is proposed in order to really solve the problem, in the continuous trial and error to find the most suitable method, and also according to the actual situation of the different timely adjustment and adaptations, in order to effectively solve the problem. Not the more policies proposed the better, but the more effective the better. Many published policies only propose goals, such as mitigating the heat island effect, slowing down climate warming, and reducing carbon emissions to X% by 2050, but do not propose practical methods. I think this happens because those proposing the policy believe that the solutions to the problems faced by different countries and regions are not identical, that there is no approach that applies to all situations, or that the solutions known to work have not been tested worldwide. Also, urban development is always rapidly changing and has to be considered in conjunction with other local policies, culture, and other aspects.\nIn addition, what I find interesting is that both the C40, a global organization’s proposal to mitigate the urban heat island effect and cool the city, and the New York government’s proposal to add cool roofs to buildings is a quick fix compared to expanding green space in the city, but it may not be a long-term solution. Perhaps the decision maker should consider the cost, efficiency and effectiveness of the solution when making the final decision.\n\nWhat is useful for the future?\n\nWhat I found useful this week for my future study and life is that I learned about the impact of urban heat island effect, related policies to mitigate urban heat island effect and case studies on urban heat island effect, so that I can pay more attention to the impact of urban heat island effect in my future life, such as the impact on human health and environment. In terms of study and research, I will probably focus more on studying policies that only propose goals but do not give effective solutions, and try to propose feasible solutions based on what I have learned about remote sensing and GIS. I hope to make a small contribution to the human environment and the earth through our own efforts and more people will join such an industry.\n\n\n\n\nBureau, US Census. n.d. “New York State Population Topped 20 Million in 2020.” https://www.census.gov/library/stories/state-by-state/new-york-population-change-between-census-decade.html.\n\n\nEnvironment, U. N. 2021. “Beating the Heat: A Sustainable Cooling Handbook for Cities.” http://www.unep.org/resources/report/beating-heat-sustainable-cooling-handbook-cities.\n\n\nFuleihan, Dean, Dominic Williams, and Daniel A Zarrilli. n.d. “THE CITY OF NEW YORK MAYOR BILL DE BLASIO.”\n\n\nGaffin, S. R., C. Rosenzweig, R. Khanbilvardi, L. Parshall, S. Mahani, H. Glickman, R. Goldberg, R. Blake, R. B. Slosberg, and D. Hillel. 2008. “Variations in New York City’s Urban Heat Island Strength over Time and Space.” Theoretical and Applied Climatology 94 (1-2): 1–11. https://doi.org/10.1007/s00704-007-0368-3.\n\n\nJennifer, Vanos, Kalkstein Laurence, Sailor David, Shickman Kurt, and Sheridan Scott. n.d. “Assessing the Health Impacts of Urban Heat Island Reduction Strategies in the Cities of Baltimore, Los Angeles, and New York.” https://www.adaptationclearinghouse.org/resources/assessing-the-health-impacts-of-urban-heat-island-reduction-strategies-in-the-cities-of-baltimore-los-angeles-and-new-york.html.\n\n\nMullerova, Daniela, and Meredith Williams. 2019. “Satellite Monitoring of Thermal Performance in Smart Urban Designs.” Remote Sensing 11 (19): 2244. https://doi.org/10.3390/rs11192244.\n\n\n“NYC CoolRoofs.” n.d. https://www.c40.org/case-studies/nyc-coolroofs/.\n\n\nPeng, Jian, Qianyuan Liu, Zihan Xu, Danna Lyu, Yueyue Du, Ruilin Qiao, and Jiansheng Wu. 2020. “How to Effectively Mitigate Urban Heat Island Effect? A Perspective of Waterbody Patch Size Threshold.” Landscape and Urban Planning 202 (October): 103873. https://doi.org/10.1016/j.landurbplan.2020.103873.\n\n\nShaker, Richard R., Yaron Altman, Chengbin Deng, Eric Vaz, and K.Wayne Forsythe. 2019. “Investigating Urban Heat Island Through Spatial Analysis of New York City Streetscapes.” Journal of Cleaner Production 233 (October): 972–92. https://doi.org/10.1016/j.jclepro.2019.05.389.\n\n\nYamamoto, Yoshika. 2006. “Measures to Mitigate Urban Heat Islands.”"
  },
  {
    "objectID": "Week3.html#summary",
    "href": "Week3.html#summary",
    "title": "3  Week 3 Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nSummary part of the learning diary in this week including two sections, one is summary for lecture, the other is summary for practical.\n\n3.1.1 Summary for lecture\nDifferent sensors may have different ways of taking images, some are similar to push broom (Fig.1), such as SPOT and Quickbird, while sensors like Landsat satellites collect data like whisk broom (Fig.1), in which case the scan line corrector (SLC) is important to control and correct the course and direction of the scan line. Since Landsat 7 did not add SLC, there are gaps between the collected data (Fig.2) and it is difficult to fill in the missing data.\n\n\n\nFig.1 principle of push broom and whisk broom sensor. Source: India Water Portal (2012)\n\n\n\n\n\nFig.2 Scan line with and without the scan line corrector. Source: Landsat Missions (n.d.)\n\n\n\n3.1.1.1 Part1: imagery corrections\nDepending on the quality of the acquired data and the needs of the user, the collected raw data is usually first corrected, which includes geometric correction, atmospheric correction, topological correction and radiometric calibration.\n\nGeometric correction\n\nWe need to do geometric correction is because the following four conditions may occur during the data collection process to cause image distortions. First is the capture of images due to the difference in view angles may cause the shadow of the objects on the image or the shadow of the aircraft sensors. Secondly, it is influenced by the topography, for example, the mountain is not a flat surface but has to be “printed” on a two-dimensional image. Thirdly, affected by weather, such as winds, heavy rain and other bad weather, sensors such as those carried by airplanes and balloons are unable to collect data stably, which can also cause image distortion. Last but not least, it is also possible that the rotation of the Earth makes the adjacent images misaligned and not perfectly aligned.\nThe principle of geometric correction is to determine some ground control points (GCP) with coordinates after selecting the target image (uncorrected image) and the reference image (corrected image), which means that we need to collect GPS data as well. In addition, to establish a function (e.g linear, polynomial, projective, etc.) based on the mathematical relationship between the positions of these GCPs in the uncorrected image and corrected image. The complete image is corrected according to this function, and the geometrically corrected image is obtained. Following Figure 3 is an example for comparing the difference between the same image before and after geometric correction.\n\n\n\nFig.3 Comparison between the same image before and after geometric correction. Source: Xue, Wang, and Zhong (2021)\n\n\nNotice:\n\nIt is also needed to minimize the RMSE value, usually less than 0.5. Add more GCPs might decrease the RMSE.\nThe points after rectified may not fall on the grid squares, and even some might fall outside the boundary. To solve this problem, we can do re-sample based on suitable methods to let the pixels in the output grids have normal values.\n\n\nAtmospheric correction\n\nAccording to Jensen (2015), atmospheric scattering and topographic attenuation are the most two important sources of environment attenuation. We perform atmospheric correction to reduce the effect of clouds on the image and reduce the contrast of the image. For example, since clouds are very bright, they would cause an adjacency effect that makes the surrounding pixels brighter than they really are. There are two types of atmospheric correction, one is relative atmospheric correction, the other is absolute atmospheric correction. Absolute atmospheric correction (e.g. FLAASH, empirical line correction) is changing digital brightness values into scaled surface reflectance, which can use atmospheric radiative transfer models, but it would be really hard, since it needs a lot of data and a long-time period to do this.\nDark object subtraction (DOS) and Psuedo-invariant Features (PIFs) are two relative atmospheric correction methods. Dark object subtraction (DOS) is based on the assumption that the reflectance of dark objects in images (e.g., bodies of water, shadows of mountains, etc.) has almost no reflectance in some specific wavelength bands, and therefore the reflectance corresponding to these dark objects in the image should be a fraction of the energy absorbed by the sensor after the solar radiation is directly reflected by the atmosphere (blamannen 2011). Therefore, by subtracting the value corresponding to the darkest object pixel in the image, a higher contrast image that is closer to the real situation is obtained. While PIFs are matching the brightness pixels in the remote sensing images and the spectral reflectance data measured simultaneously using a field spectrometer in the linear relationship, and use linear regression to adjust (predict) the values of other pixels in the image to be corrected.\nHowever, it is not always necessary to do atmospheric correction, such as when classifying a single image, independent classification of multiple date imagery, and other situation (Jensen 2015).\n\nTopological (orthorectification) correction\n\nThe essence of topological correction is to computationally adjust the image looks same as the view at nadir look and remove distortions, which requires sensor geometry and an elevation model. Topological correction can be done by using software like QGIS and SAGA GIS, or R as well.\nNotice: Atmospheric correction should be done before topological correction.\n\nRadiometric calibration\n\nRadiometric calibration is based on the raw data collected from the satellites to change digital numbers (DN) into spectral radiance, which means that change image brightness into the amount of light within a band from a sensor in the field of view (FOV). After the transmission, the spectral radiance is with units and meaning.\n\n\n\n\n\n\nNotice\n\n\n\n\nDNs do not have units.\nRadiance is usually called top of atmosphere radiance.\nLevel 2 product refers to the data has been changed or advanced.\n\n\n\n\n\n3.1.1.2 Part2: data joining and enhancement\nData joining is like merging imagery together. In many cases, we need to join data sets to generate a complete remote sensing image covering the whole study area when the study area is relatively large or located at the junction of multiple images. In the process of joining, the average of the pixel values of the overlapping parts is usually chosen as the pixel value of the joined images. The reason for doing so is to reduce the difference of DN values between the two images.\nImage enhancement refers to the enhancement of image contrast because many different materials may have little difference in their ability to reflect the same wavelength of energy, which may cause the range of DNs of the raw image to be concentrated in a smaller range, resulting in a lack of significant contrast and the need for contrast enhancement. Common methods include expand the range of DNs from Minimum to Maximum, percentage linear and standard deviation, and piecewise linear contrast stretch. In addition, there are many other enhancement which can be applied to improve the quality and visual appearance of the imagery, including ratio enhancement, filtering (e.g. edge enhancement), PCA texture enhancement, pan sharpen and data fusion (decision level fusion, object-level fusion, image fusion and satellites data fusion).\nNotice: Image stretch only change how the image express by stretching the range of original image in a more suitable range, it does not change the raw image.\n\n\n\n3.1.2 Summary for practical\nIn this week’s practical part, we mainly focus on three parts, including atmosphere correction, imagery merge, and image enhancement. In practical applications, these are important steps for the pre-processing of acquired original remote sensing images, because it is never possible to obtain the most ideal image. The main workflow of practical in this week shows in the following Figure 4. According to the workflow, it shows that our main task is to actually apply these image processing methods, review what we talked about in the lecture and what they should be used for.\n\n\n\nFig.4 Workflow of Practical in Week 3\n\n\nAccording to Figure 4 above, I divided this practical into 3 parts. The first part is for atmosphere correction, and I focused on one of the atmosphere correction methods called Dark Object Subtraction (DOS) in this week. As mentioned above in the summary of lecture part, DOS is an approach based on the fact that very dark objects do not reflect any energy back to the sensor, so subtract that energy and the image appears unaffected by the atmosphere. Following is the R code that we can use to do DOS in R, and based on the function radCor( ) and relevant parameter settings, we can get the result after DOS in a quick way without manual calculation. In addition to DOS, it is also mentioned to convert the DN value of the image directly into reflectance, that is, the reflectance of the Top of Atmosphere.\n\n#boa_ref <- radCor(lsatMeta, metaData, method = \"dos\")# surface reflectance with DOS\n#lsat_rad <- radCor(lsatMeta, metaData = metaData, method = \"rad\")# Radiance\n#hazeDN    <- RStoolbox::estimateHaze(lsat, hazeBands = 2:4, darkProp = 0.01, plot = TRUE)\n#lsat_sref <- radCor(lsatMeta, metaData = metaData, method = \"dos\",hazeValues = hazeDN, hazeBands = 2:4)\n\nIn part 2, after I did pre-processing for the imagery that I collected, I merged two images by using mosaic( ) function in the terra package in R. In this case, the method of mean value is adopted to deal with the overlapping parts between two images. In part 3, I tried 5 image enhancement approaches, including ratio enhancement, filtering, texture enhancement, data fusion & PCA. In the part of ratio enhancement, I used Normalised Difference Vegetation Index (NDVI) to enhance the vegetation coverage in the image (Figure 5), while Normalized Difference Moisture Index (NDMI) could enhance the area with high moisture in the image (Figure6). in this case, the results of NDVI and NDMI looks similar.\n\n\n\nFig.5 Area with NDVI value higher than 0.2 (relative high vegetation cover rate in Cape Town)\n\n\n\n\n\nFig.6 Area with NDMI value lower than -0.2 (relatively high mositure in Cape Town)\n\n\nFor texture enhancement, I chose Band 4. According to the spectral feature curve of the surface object, the enhanced part should be green vegetation, which can be confirmed by Figure 7 below. This method may be used for image enhancement with higher resolution and large differences in surface objects, which may get more obvious enhancement effect.\n\n\n\nFig.7 Texture enhancement result\n\n\n\n\n\n\n\n\nNotice\n\n\n\n\nFormula of DOS, and the meanings of these indices in the formula.\nUsually, do not use panchromatic band when doing land cover classification.\n\n\n\n\n\n3.1.3 Questions\n\nHow many GCPs do we need to select when doing geometric correction?\nWhy atmospheric correction is not always necessaryly done?\nWhat is the difference between empirical line correction and PIFs, both of them correct image based on regression model?\nHow to convert TOA radiance to TOA reflectance?\nWhat is the light source when mention TOA reflectance and surface reflectance?\nIs pan sharpen a kind of high pass enhancement? if not, what is the difference between them?\nWhy color of pixels outside the overlapping area of the following images also changed after joining?\n\n\n\n\nFig.4 Comparison between two images before and after joining.\n\n\n\nAfter doing PCA, how to interpret the results? What is the components refer to?"
  },
  {
    "objectID": "Week3.html#application",
    "href": "Week3.html#application",
    "title": "3  Week 3 Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application"
  },
  {
    "objectID": "Week3.html#reflection",
    "href": "Week3.html#reflection",
    "title": "3  Week 3 Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nWhat is interesting?\nI think the interesting thing in this week is that the image that the sensor gets can be significantly different from the actual scene, for example, due to the influence of particles in the atmosphere. However, the effect of atmosphere on image quality can be minimized by atmospheric correction. It can also improve the quality of the image through image enhancement, so that users can distinguish the ground objects more clearly. For example, by calculating NDVI, green vegetation with different chlorophyll contents can be roughly mastered, which can be used to monitor crop diseases and insect pests and other practical problems.\nWhat is useful in the future?\nBoth atmospheric correction and image enhancement should be done after obtaining the original remote sensing image, but there may be differences according to different research purposes. For example, the color contrast of the image after atmospheric correction is more stark than that of the original image. Whether it is supervised classification, unsupervised classification or visual discrimination, it can be clearer and help to get more accurate classification results. And image enhancement also has a wide range of applications, such as the NDMI image can be preliminarily found flood areas.\nWhat is not useful? (can be instead)\nIn my opinion, neither atmospheric correction nor image enhancement can be instead so far, but the quality of some original satellite data is very high or the research questions studied by some scholars are relatively special, so it may be unnecessary to carry out the image preprocessing of atmospheric correction and image enhancement.\n\n\n\n\nblamannen. 2011. “Landsat Data Processing (in ENVI).” https://blamannen.wordpress.com/2011/05/01/landsat-data-processing-in-envi/.\n\n\nIndia Water Portal. 2012. “Remote Sensing Application in Agriculture & Forestry_dr Menon a r r (…,” December. https://www.slideshare.net/indiawaterportal/remote-sensing-application-in-agriculture-and-forestry-menon-a-r-r.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. Old Tappan: Pearson Education.\n\n\nLandsat Missions. n.d. “Landsat 7.” https://www.usgs.gov/landsat-missions/landsat-7.\n\n\nXue, Wu, Peng Wang, and lingyu Zhong. 2021. “Geometric Correction of Optical Remote Sensing Satellite Images Captured by Linear Array Sensors Circular Scanning Perpendicular to the Orbit.” Changchun: Chinese Academy of Sciences Vol.29 (12): p.2924–2934. https://d-wanfangdata-com-cn.libproxy.ucl.ac.uk/periodical/ChlQZXJpb2RpY2FsQ0hJTmV3UzIwMjMwMTEyEg9neGptZ2MyMDIxMTIwMTcaCHBheDgxcGlx."
  },
  {
    "objectID": "Week1.html#summary",
    "href": "Week1.html#summary",
    "title": "1  Week 1 Getting started with remote sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nRemote sensing was first created for military and warfare purposes, but is now also used in a wide range of civilian applications (Brady 2021).\n\n1.1.1 Summary of lecture\nIn fact, in our real life, applications for remote sensing are relatively common and there are a large number of satellites currently in use (Garcia 2015).\nRemote sensing can be generally divided into two types based on different types of sensors, one is passive sensor, the other is active sensor. Passive sensor usually does not emit anything, it just reflects energy (electromagnetic waves) from the sun, for instance, satellite sensor. Active sensor emits electromagnetic waves actively and receive the energy back, such as Radar and LIDAR. The following picture shows the difference between passive remote sensing and active remote sensing.\n\n\n\nFig.1 Schematic diagram of the principles of active and passive remote sensing. Source:\n\n\nThere is a term called radiation budget, which consists of four components, including energy entering, reflected, absorbed, and emitted by the Earth system , and is mainly used to evaluate the degree to which energy is balanced through the more complex processes of propagation, absorption, and reflection (Butcher 2016).\n\n\n\nFig.2 Radiation budget. Source: Butcher (2016)\n\n\nTherefore, electromagnetic radiation (EMR) from the sun is different with the energy arrive the earth surface, since the energy can be scatter by the atmosphere. Atmosphere scatter can be divided into three types, including Rayleigh, Mie and non selective, which is depends on the sizes of particles and the wavelengths.\nThese scattering phenomena are also very common in everyday life, for instance, the sky is blue is because Raleigh scattering happens. Similarly, we can explain the black sky in the space and blue ocean. Remote sensing is based on the identification of different types of features through the unique spectral signatures formed by the different reflections and absorptions of features in response to EMR (Brady 2021).\n\n\n\nFig.3 Spectral curves of characteristic features. Source: Butcher (2016)\n\n\nHowever, passive remote sensing has a very large disadvantage that the quality of imagery depends on the weather and cloud cover. We can solve this problem by using active sensors, for instance, Synthetic Aperture Radar (SAR), which can see through clouds, volcanic ash, and other bad atmospheric conditions based on longer wavelengths.\nRemote sensing imagery is raster data, but there are a variety of data storage formats, including band interleaved by line, band sequential, band interleaved by pixel, and GeoTIFF.\nThere are four resolutions to describe the quality or characteristics of the imagery, including spatial resolution (size of raster cells), spectral resolution (define the shortest wavelength intervals), temporal resolution (revisit time), and radiometric resolution (the ability to detect the smallest differences in energy, or the sensitivity of the sensor).\nAbout the orbits of the sensors, there are geosynchronous obits and geostationary orbits.\nAdvantages and Disadvantages of remote sensing Jensen (2015)\nNotice:\n\nThe direction of sunlight might influences the image, and may even affect the interpretation of the images.\nSpectral signatures can be discrete and continuous.\n\n\n\n1.1.2 Summary of practical\nThe practical part of this week mainly focus on using QGIS and SNAP two software to get familiar with remote sensing satellite images and preliminarily understand the supervised classification of images, and intuitively understand the difference of land use in the study area and the difference of spectral characteristics of different land use types through statistical maps. This is very important for the next few weeks of study. Although I may not rely too much on software such as SNAP to process and analyze remote sensing images, it can help me understand the meaning of corresponding R codes and the content in the course. Following Figure 4 is the overall workflow of the practical in this week.\n\n\n\nFig.4 Workflow of Practical in Week1\n\n\nThe first main session is that I downloaded Sentinel-2 data from Copernicus Open Access Hub website based on several criteria and loaded data into QGIS first to try to use familiar software (QGIS) to get familiar with the academic terms we learnt in the lecture, including true color satellite image, spectral signature, and raster stack. I also did down-scaling and up-scaling based on QGIS resampling tool to make all the bands that I collected are with the same resolution (image enhancement) before subsequent process and analysis.\nThe second main section is create Tasseled Cap within the study area after mask and resample the imagery to get three more bands, including brightness, greenness, and wetness. The process of generating Tasseled Cap is a process to transform original data into a new data set with reducing the dimensions and maximizing the variance. Based on the different values of brightness, greenness and wetness correspond to different degrees of brightness, greenness and wetness, which can provide a preliminary understanding of land use types in the study area. Light areas in brightness image (Figure 5) should be bare soil, man-made surface, or areas covered by other bright materials. In the greenness image (Figure 6), green vegetation, such as forest, grassland and crops, can be clearly distinguished. In the wetness image (Figure 7), I can mainly distinguish the place with high moisture, such as pond, lake, and river.\nThree components of Tasseled Cap formulas based on Sentinel imagery:\n\\(Brightness = 0.3037(B2)+0.2793(B3)+0.4743(B4)+0.5585(B8)+0.5082(B11)+0.1863(B12)\\)\n\\(Greenness = -0.2848(B2)-0.2435(B3)-0.5436(B4)+0.7243(B8)+0.0840(B11)-0.1800(B12)\\)\n\\(Wetness = 0.1509(B2)+0.1973(B3)+0.3279(B4)+0.3406(B8)-0.7112(B11)-0.45(B12)\\)\n\n\n\nFig.5 Brightness generate from Sentinal-2 image\n\n\n\n\n\nFig.6 Greenness generate from Sentinel-2 image\n\n\n\n\n\nFig.7 Wetness generate from Sentinel-2 image\n\n\nThe third section in this practical is creating five types of land use sample polygons shared by Landsat and Sentinel images were selected, including urban, water body, grassland, forest and bare soil, and export the drawn polygons and remote sensing images after mask and resampling to R studio. After that, I created two graphs show the mean and standard deviation of 5 types of POIs vs. band values of both Sentinel-2 and Landsat imagery, and two graphs are the density plots for the distributions of 5 types of land use with different band values of both Sentinel-2 and Landsat imagery. The mean and standard deviation of five types of land use pixels selected in study area vs. band values plot and density of different categories of land use pixels selected in the study area vs. band values graph of Sentinel-2 imagery show in the following Figure 8, and similar plots of Landsat-8 imagery show in Figure 9 below.\n\n\n\nFig.8 Mean and standard deviation of five types of land uses (A) and density plot (B) in the selected Sentinel-2\n\n\n\n\n\nFig.9 Mean and standard deviation of five types of land uses (A) and density plot (B) in the selected Landsat-8 imagery\n\n\nAs can be seen from Figure A in Figure 8 and 9 above, when green vegetation, such as grassland and forest, is extracted from remote sensing images, red band and near infrared band can be mainly used, because there is a significant difference in pixel values between them and other bands. This feature is universally applicable to Sentinel-2 and Landsat-8 images. In addition, it can be seen from Figure B in FIG. 8 and FIG. 9 that water bodies are concentrated in a relatively small band value, while other land use types are not highly concentrated in a relatively narrow band range. This feature allows us to extract water from images with high accuracy.\nThere are some practical limitations. First of all, different research areas, time and other conditions correspond to different images. Some areas may not have rich land use types, or the contrast of land use types is not obvious, which may result in a low difference in results. In addition to different sensors, the differences in FIG. 8 and FIG. 9 May also result from different time of image acquisition, resulting in differences in spectral features of the same ground objects acquired. In addition, when SNAP creates polygons representing the five land use types, it may not be enough or representative enough, so that the results in Figure 8 and 9 May not fully meet the general applicability, but the general trend of change is similar.\n\n\n\n\n\n\nNotice\n\n\n\n\nSNAP is another GIS software specific to Sentinel, which can be access to resampling, reproject, masking, classifying, PCA, and many other processing and analyzing methods.\nBefore the subsequent process after load the data into R Studio, it is needed to unify the coordinate systems of the two images.\nVector data need to be converted into SpatVector in R.\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n1. Why when TCI values are coded between 0 and 255 and radiometric resolution of Sentinel-2 is 12-bit means brightness levels from 0 and 4095 cannot be clear how this product has been made?"
  },
  {
    "objectID": "Week1.html#application",
    "href": "Week1.html#application",
    "title": "1  Week 1 Getting started with remote sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\n\n1.2.1 Passive remote sensing application\nThere are many examples of passive remote sensing applications. For example, the near-infrared (NIR) band is important for passive remote sensing. The NIR band can be used in applications such as monitoring vegetation growth, crop pests and diseases (Butcher 2016). The main reason for this is that healthy vegetation absorbs red and blue light to synthesise chlorophyll, and the more chlorophyll is synthesised, the stronger the NIR reflection (Butcher 2016). In addition, Ramos et al. (2020) assessed soil salinity in Portugal based on vegetation indices computed from Sentinel-2 images.\nIn this learning diary, I will mainly summarize some examples of passive remote sensing applications based on Landsat and Sentinel series satellite imagery. Medium-resolution images like Landsat 8 and Sentinel-2 are more representative of the interactions between human and nature, and are more commonly used in studies targeting passive remote sensing because of the short revisit period of both satellites and the data are free (E. D. Chaves, C. A. Picoli, and D. Sanches 2020). Below are two relatively typical, specific examples of applying Sentinel-2 and Landsat 8 satellite imagery.\n\n1.2.1.1 Application based on Sentinel data\nLlorens et al. (2021) explored a method for simulating the area burned and the extent of forest damage following a forest fire on the border between Spain and northern Portugal, based on Sentinel-2 level 2A data. By comparing the spectral profiles of remote sensing images of this forest before and after the forest fire, Llorens et al. (2021) found that reflections in the green and near-infrared bands decreased significantly after the fire, while reflections in the short-wave infrared band increased more significantly. Therefore, Llorens et al. (2021) created Normalized Burn Ratio (NBR) and differenced NBR (dNBR) parameters to identify the surface of the fire and the severity of the burn. Finally, they concluded that this method is accepted for determine burn area and damage after forest fire. The authors chose to use Sentinel-2 data might because the high spatial resolution and short revisit time with low cloud cover and the data must be obtained as close as possible to the period of the forest fire.\n\n\n\nFig.6 Sentinel-2 dNBR image and simulation dNBR in EFFIS image. Source: Llorens et al. (2021)\n\n\nIn my opinions, based on their comparison of the simulated results with actual GPS data and more accurate remote sensing data, the dNBR coefficients calculated by Sentinel-2 are more accurate when applied to EFFIS data for the assessment of burn severity level after forest fires. Since Sentine-2 data has 4 more bands in the Red Edge spectral region (Segarra et al. 2020), I deem that the authors chose the relatively suitable data and methods as well. However, this method has only been applied to this one scenario and has not been applied to other forests in different situations, so it is not very rigorous to conclude that this method is accurate.\n\n\n1.2.1.2 Application based on Landsat data\nAs the Landsat series of satellites evolved from generation to generation to Landsat 8, the spatial resolution of 30m was still retained, but the quantization was enhanced by carrying two sensors, OLI and TIRS (Hemati et al. 2021). In recent years, Landsat imagery has been widely used because of the thermal infrared band, which is applied to mine exploration and predicting mineral production (Frutuoso, Lima, and Teodoro 2021); and because the Landsat series of satellites collects remote sensing images uninterruptedly since the first satellite was launched in 1972 until 2023, Landsat imagery can be applied to long-term studies of land use and land cover type changes (Potapov et al. 2020).\nWith the rapid growth of cities around the world, the urban heat island effect is also increasing, and the average land surface temperature continues to grow (Amindin et al. 2021). Amindin et al. (2021) used Landsat 4, 5, 7, 8 images to compute land surface temperature, urban thermal field variance index and urban heat island index to investigate the intensity of urban heat island effect in Ahvaz, Iran and the change of distribution from 1995 to 2016. Amindin et al. (2021) finally found that the green area decreased by 50% and the area with high surface temperature expanded during this 21-year period.\n\n\n\nFig.7 Composite map of UTFVI and UHI index of Ahvaz. Source: Amindin et al. (2021)\n\n\nI think their data selection is reasonable, because they need data with a large time span for analysis, and Landsat series data can meet this requirement, and the spatial resolution of Landsat 4, 5, 7, 8 images selected by the authors is 30m and they can both be used directly to calculate the LST, which can simplify the task of data processing part. In terms of analysis, they used support vector machine method for land use classification and quantified the impact of urban heat island effect by two parameters (UHI and UTFVI). Based on its land use classification accuracy (93%) and the comparison of the LST distribution and the plots combining UHI and UTFVI together, the feasibility, reproducibility, and accuracy of these methods are relatively high. However, other land use classification methods can also be tried to improve the accuracy of the classification.\n\n\n\n1.2.2 Active remote sensing application\nThe quality of passive remote sensing images may be negatively affected by receiving weather effects, while active remote sensing avoids this problem and can collect images day and night because electromagnetic radiation emitted by the sun is not required. Therefore its applications are also very wide (GISGeography 2015).\nZhang et al. (2019) used SAR and LIDAR data to capture changes in crops due to pests and diseases, and they also compared the use of visible and near-infrared bands in remote sensing imagery to monitor crop pests and diseases, but the point of using SAR and LIDAR data is to monitor pests and diseases that tend to breed in wet and cloudy weather, or crop morphology that is susceptible to changes due to pests and diseases. I think this approach has a great advantage because the data obtained is of high resolution and can be used to monitor very small changes without being affected by weather conditions.\nHe et al. (2019) monitored the illegal buildings based on the high-resolution unmanned aerial vehicle (UAV) remote sensing images and the acquired SAR data, and build 3D models for the illegal buildings in ArcGIS for further judgment. I think this method can find the illegal building more accurately and determine whether the illegal building has been demolished according to the regulations. In addition, the UAV remote sensing images can acquire data at any time according to the research needs. However, UAV remote sensing is less efficient in acquiring data and is not suitable for situations where the study area is large. It is also necessary to bear all the costs associated with the UAV and to master the UAV piloting skills. Therefore, the reproducibility of the method may not be high.\nSurdu et al. (2014) collected a total of 78 SAR data from 1991 to 2011 to monitor the changes in floating ice coverage, thickness and grounded ice. Surdu et al. (2014) found that there is an increasing trend of floating ice and a decreasing trend of grounded ice. In addition, there is an increasing trend in the number or quantity of lakes that maintain liquid water under floating ice, and the ice cover thins in winter (Surdu et al. 2014).\n\n\n\nFig.8 Floating ice and grounded ice change from 1991 to 2011 in Arctic shallow lakes. Source: Surdu et al. (2014)\n\n\nI deem that the data they chose is more appropriate, and since it needs to go through thick ice, maybe radar data is more appropriate than remote sensing images. Secondly, they chose the date of the radar data, and almost chose the data from the period when the data quality was high and the ice was the thickest. However, since this study is relatively early, there are not yet many high-precision remote sensing images available to assist their study, so perhaps trying to incorporate high-resolution remote sensing images may help improve the accuracy of the study if newer techniques can be combined."
  },
  {
    "objectID": "Week1.html#reflection",
    "href": "Week1.html#reflection",
    "title": "1  Week 1 Getting started with remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nWhat is interesting?\nI think the idea of taking pictures of the Earth from a distance was a very novel idea in the 1960s, and remote sensing has evolved to the point where there are several series of satellites, different uses of satellites, and even vehicle-mounted devices, drones and other devices that can be used as tools to access remote sensing data. In addition, software for processing remote sensing data has become increasingly available.\nAfter learning about the characteristic spectral curves of features, I found it interesting that the spectral curves of grasslands and forests can be significantly different even if they do not look very different to the human eye on remote sensing images. And while the spectral curves of forests formed by different types of trees may not be identical, the trends are very similar.\nWhat is useful in the future?\nAfter understanding the basics of remote sensing and examples of research using different remote sensing techniques and data, I have a deeper understanding of the characteristics of Landsat and Sentinel satellite data, which will help me a lot in choosing the right data when doing related research in the future. In addition, by looking up literature and understanding the application of remote sensing techniques in practical research, it was useful for me to understand the content in class, expand my horizon, and choose a topic for my thesis.\nIf the opportunity arises, I may in the future investigate the combination of agent-based modelling and remote sensing to explore the impact of forest fires and in this way quantify the negative impact of forest fires.\nWhat is not useful? (can be instead)\nI think what I have learned so far this week has been useful because as learning and understanding remote sensing as a technology requires introducing conceptual knowledge first, rather than exploring an aspect in depth. However, remote sensing images are easily affected by weather, such as cloud cover, and the steps and principles of pre-processing remote sensing images can be introduced first, before introducing active remote sensing may be more complete.\n\n\n\n\nAmindin, Atiyeh, Soheila Pouyan, Hamid Reza Pourghasemi, Saleh Yousefi, and John P. Tiefenbacher. 2021. “Spatial and Temporal Analysis of Urban Heat Island Using Landsat Satellite Images.” Environmental Science and Pollution Research 28 (30): 41439–50. https://doi.org/10.1007/s11356-021-13693-0.\n\n\nBrady, Maria. 2021. “Remote Sensing for Dummies.” https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d.\n\n\nButcher, Ginger. 2016. Tour of the Electromagnetic Spectrum. Third edition. Washington, DC: National Aeronautics; Space Administration.\n\n\nE. D. Chaves, Michel, Michelle C. A. Picoli, and Ieda D. Sanches. 2020. “Recent Applications of Landsat 8/OLI and Sentinel-2/MSI for Land Use and Land Cover Mapping: A Systematic Review.” Remote Sensing 12 (18): 3062. https://doi.org/10.3390/rs12183062.\n\n\nFrutuoso, Rui, Alexandre Lima, and Ana Cláudia Teodoro. 2021. “Application of Remote Sensing Data in Gold Exploration: Targeting Hydrothermal Alteration Using Landsat 8 Imagery in Northern Portugal.” Arabian Journal of Geosciences 14 (6): 459. https://doi.org/10.1007/s12517-021-06786-0.\n\n\nGarcia, Mark. 2015. “Space Debris and Human Spacecraft.” http://www.nasa.gov/mission_pages/station/news/orbital_debris.html.\n\n\nGISGeography. 2015. “Passive Vs Active Sensors in Remote Sensing.” https://gisgeography.com/passive-active-sensors-remote-sensing/.\n\n\nHe, Yuanrong, Weiwei Ma, Zelong Ma, Wenjie Fu, Chihcheng Chen, Cheng-Fu Yang, and Zhen Liu. 2019. “Using Unmanned Aerial Vehicle Remote Sensing and a Monitoring Information System to Enhance the Management of Unauthorized Structures.” Applied Sciences 9 (22): 4954. https://doi.org/10.3390/app9224954.\n\n\nHemati, MohammadAli, Mahdi Hasanlou, Masoud Mahdianpari, and Fariba Mohammadimanesh. 2021. “A Systematic Review of Landsat Data for Change Detection Applications: 50 Years of Monitoring the Earth.” Remote Sensing 13 (15): 2869. https://doi.org/10.3390/rs13152869.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. Old Tappan: Pearson Education.\n\n\nLlorens, Rafael, José Antonio Sobrino, Cristina Fernández, José M. Fernández-Alonso, and José Antonio Vega. 2021. “A Methodology to Estimate Forest Fires Burned Areas and Burn Severity Degrees Using Sentinel-2 Data. Application to the October 2017 Fires in the Iberian Peninsula.” International Journal of Applied Earth Observation and Geoinformation 95 (March): 102243. https://doi.org/10.1016/j.jag.2020.102243.\n\n\nPotapov, Peter, Matthew C. Hansen, Indrani Kommareddy, Anil Kommareddy, Svetlana Turubanova, Amy Pickens, Bernard Adusei, Alexandra Tyukavina, and Qing Ying. 2020. “Landsat Analysis Ready Data for Global Land Cover and Land Cover Change Mapping.” Remote Sensing 12 (3): 426. https://doi.org/10.3390/rs12030426.\n\n\nRamos, Tiago B., Nádia Castanheira, Ana R. Oliveira, Ana Marta Paz, Hanaa Darouich, Lucian Simionesei, Mohammad Farzamian, and Maria C. Gonçalves. 2020. “Soil Salinity Assessment Using Vegetation Indices Derived from Sentinel-2 Multispectral Data. Application to Lezíria Grande, Portugal.” Agricultural Water Management 241 (November): 106387. https://doi.org/10.1016/j.agwat.2020.106387.\n\n\nSegarra, Joel, Maria Luisa Buchaillot, Jose Luis Araus, and Shawn C. Kefauver. 2020. “Remote Sensing for Precision Agriculture: Sentinel-2 Improved Features and Applications.” Agronomy 10 (5): 641. https://doi.org/10.3390/agronomy10050641.\n\n\nSurdu, C. M., C. R. Duguay, L. C. Brown, and D. Fernández Prieto. 2014. “Response of Ice Cover on Shallow Lakes of the North Slope of Alaska to Contemporary Climate Conditions (19502011): Radar Remote-Sensing and Numerical Modeling Data Analysis.” The Cryosphere 8 (1): 167–80. https://doi.org/10.5194/tc-8-167-2014.\n\n\nZhang, Jingcheng, Yanbo Huang, Ruiliang Pu, Pablo Gonzalez-Moreno, Lin Yuan, Kaihua Wu, and Wenjiang Huang. 2019. “Monitoring Plant Diseases and Pests Through Remote Sensing Technology: A Review.” Computers and Electronics in Agriculture 165 (October): 104943. https://doi.org/10.1016/j.compag.2019.104943."
  },
  {
    "objectID": "Week5.html#summary",
    "href": "Week5.html#summary",
    "title": "5  Week 5 Google Earth Engine I",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nIn this week, we focus more on what is Google Earth Engine, and how to use it to solve the real world problems. Meanwhile, we will also summary important points and outputs in this week practical for reviewing.\n\n5.1.1 Google Earth Engine (GEE) introduction\nGEE is an online mapping platform which is based on Javascript. With R and QGIS we learnt in CASA0005, and Python we learnt in CASA0013 in the last term, it may be a little easier to understand Javascript after learning and applying them in practice.\nGEE has client side and server side, and there are some differences between them that should be noted in practice. For instance, we cannot use loop in the server side, but we can use mapping function in the server side. That is because that the data, including shapefile, table, and other types of data, that we upload will be stored in client, so that server does not know what objects are used for looping.\nScale in GEE refers to pixel resolution, and it might return different values for the scales based on different specific analysis. What we need to pay more attention is that we need to set scale in the script window in GEE, or else the scale will change every time after we adjust the scale in the map window in GEE.\nFor projection, GEE sets the default projection coordinate system and converts all data to this coordinate system. In practice, there is an option to import the processed data from GEE into software such as QGIS and convert the coordinate system to the one we need.\n\n\n5.1.2 GEE in action\nThere are nine types of object classes in GEE, including Image, ImageCollection, Geometry, Feature, FeatureCollection, Reducer, Join, Array, and Chart. Image, imageCollection, Geometry , Feature, and FeatureCollection are consists of the data sets.\nReducer is more like a “groupby” in terms of functionality, which can aggregate data over time, space and other aspects, and calculate the new values of pixels based on summary statistics, linear regression, and other methods. Usually, we can choose to use median when doing reduce image is good enough, especially doing forest & non-forest, water & non-water (giant difference between two categories). Reducing images by neighbourhoods can help us to see the features which may not be clear on the raw images.\nIn addition, we can do join and spatial join in GEE as well, which is quite similar as R.\nNotice:\n\nGeometries do not have properties, while features have.\nWe need to distinguish the small differences between reducing images by regions and reducing images by region.\nWhen doing multivariate multiple linear regression, which means that we do linear regression with two dependent variables at the same time, but separately, and make sure to have a constant band.\n\n\n\n5.1.3 Summary of practical in this week\nThis week’s practical is mainly used to familiarize with the basic functions of GEE and to combine these with what we have learnt in class about remote sensing image processing in a practical way. Main workflow of practical in this week shows in the following Figure 1. Our main project is to process remote sensing images and get one image in the target study area. In this practical, we set the study area as Dheli, India.\n\n\n\nFig.1 Workflow of Practical in Week 5\n\n\nAfter we create GEE account and open GEE, we added a point of New Delhi based on the coordinates, and also we loaded Landsat images and added them to map. Then, we chose to load a shapefile document of New Delhi, load Landsat images intersect with the study area, and apply “applyScaleFactors” created by Matt Hanson to choose the better image. “applyScaleFactors” function shows in the following code chunk. Therefore, we got three images which have intersections with the study area in true color.\n\n#function applyScaleFactors(image) {\n#  var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\n#  var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);\n#  return image.addBands(opticalBands, null, true)\n#              .addBands(thermalBands, null, true);\n#}\n\nNote: The pair of values 0.0000275 & -0.2 is scale factor of surface reflectance with Landsat Level-2 collection 2, and the pair of values 0.00341802 & 149.0 are the scale factors of surface temperature (“How Do i Use a Scale Factor with Landsat Level-2 Science Products? | u.s. Geological Survey,” n.d.).\n\n\n\nFig.2 True color images intersect New Delhi after applying “applyScaleFactors” function\n\n\nIn the next step, we mosaic three images into one image and calculate mean pixel values as the pixel values of overlapped areas.\n\n\n\nFig.3 Image after merging through mosaic\n\n\nAfter clipped the image by study area shapefile and select specific bands, we got one complete satellite image inside the boundary of study area.\n\n\n\nFig.4 Clipped image of New Delhi after processing\n\n\nIn this case, we can measure texture, do PCA and add bands with high variances as a layer to the map.\n\n#var glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n#  .multiply(1000)\n#  .toUint16()\n#  .glcmTexture({size: 1})\n#  .select('SR_.._contrast|SR_.._diss')\n#  .addBands(clip);\n#// add to the map, but change the range values  \n#Map.addLayer(glcm, {min:14, max: 650}, 'glcm');\n\nNote:\n\nMultiply by 1000 is multiplying surface reflectance to compute texture.\nThe parameter size in glcmTexture() is set to 1 to set the extent of the neighbourhood to be a 3 by 3 grid.\n\nIn real world applications, the results of this step can be used to perform some analysis of New Delhi in GEE or to export this layer for analysis in the softwares, for example to calculate NDVI.\n\n\n\nFig.5 NDVI of New Delhi based on Landsat 8 images\n\n\n\n\n5.1.4 Questions\nNo question so far."
  },
  {
    "objectID": "Week5.html#application",
    "href": "Week5.html#application",
    "title": "5  Week 5 Google Earth Engine I",
    "section": "5.2 Application",
    "text": "5.2 Application\nGEE is a cloud-based storage platform for geospatial analysis built on Google’s powerful cloud computing capabilities, which allows users to use this platform to support many studies and analyses, such as in forest degradation and geological hazards(Gorelick et al. 2017).\nZhang et al. (2021) implemented monitoring of PV plants in the Ningxia Autonomous Region through GEE-based random forest mapping of PV plants. They chose to conduct their analysis on GEE, an online platform, because of its ability and efficiency to directly extract free and open source remote sensing imagery data like Landsat 8 and run large volumes of data without data storage issues (Zhang et al. 2021). However, I think that the authors have used GEE for random forests to make clever use of the advantages of the platform. Also, as an online map platform, it may be easier to complete group projects that require collaboration, but may not be suitable when the data required is not free and open source or not included in the GEE database.\nQu et al. (2021) explored ways to improve the accuracy of land use and land cover classification using remotely sensed datasets provided by GEE as well as ancillary datasets. They examined the impacts of different feature data on the accuracy of the random forest classification model with the help of six types of feature data obtained from GEE, including spectral features, topographic features, soil features, and other three aspects (Qu et al. 2021). I think this approach can reduce a lot of the time spent on finding feature data sets, and I may consider borrowing this approach to build a high-precision object-oriented classification model for random forests via GEE if a large and diverse set of feature data sets needs to be collected in future research.\nWith the GEE development aspect, users can also develop simple applications such as comparing air quality on their own (Gaertner, n.d.a). Besides that, “MODIS NDVI Slider” (n.d.) is a very representative GEE-based application developed to compare differences in NDVI between years. The development APIs included in GEE allow for more customization options and these examples highlight the versatility of GEE for data visualization.\n\n\n\nFig.6 Screenshot of Europe’s Air Quality Winner app developed by Gaertner (n.d.) based on GEE\n\n\nIn addition to the above applications, which are more oriented towards visualising the results in a different way, there are also interactive applications based on GEE, such as the GEE-based application ‘Population Rings’ developed by (Gaertner, n.d.b), which allows users to click on any location on a map to divide four areas around that point and show the line chart of the population changein each zone between 1975 and 2015.\nHowever, analysis and development based on GEE is limited by the tools provided by this platform and cannot achieve all the needs of the users (Amani et al. 2020)."
  },
  {
    "objectID": "Week5.html#reflection",
    "href": "Week5.html#reflection",
    "title": "5  Week 5 Google Earth Engine I",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThis week was spent learning about GEE, an online geospatial analysis platform. What I found interesting was that the platform not only allows for some basic vector and raster data processing and analysis, a huge open source database, but also the ability for users to develop simple applications of their own. I think GEE is a platform that can be used in future research when a large amount of open source remote sensing data is needed or when feature datasets are needed for analysis, so that there is no need to download large amounts of data, which affects efficiency, takes up a lot of memory space, and is not convenient for transferring back and forth between team members.\nHowever, if the data used in the study requires remote sensing images with a high degree of accuracy and confidentiality, it may be more appropriate to use software or programming to process them locally. In addition, the programming language used in the GEE code editor is Java, which may not be suitable for users with little or no programming skills, and it may be possible to provide code editors for other programming languages or to design a collection of tools like the toolkit for ArcGIS online. This might allow more users to experience GEE and give advice from different perspectives to help make it better.\n\n\n\n\nAmani, Meisam, Arsalan Ghorbanian, Seyed Ali Ahmadi, Mohammad Kakooei, Armin Moghimi, S. Mohammad Mirmazloumi, Sayyed Hamed Alizadeh Moghaddam, et al. 2020. “Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 13: 5326–50. https://doi.org/10.1109/JSTARS.2020.3021052.\n\n\nGaertner, Philipp. n.d.a. “Europe Air Quality Winner.” https://gaertnerp.users.earthengine.app/view/europe-air-quality-winner#cloud=10;scale=15000;ranking=absolute%20difference%20(%CE%BCmol%2Fm%C2%B2);startdate=2020-03-01;enddate=2020-04-01;\n\n\n———. n.d.b. “Population-Rings.” https://gaertnerp.users.earthengine.app/view/population-rings.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” Remote Sensing of Environment 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\n“How Do i Use a Scale Factor with Landsat Level-2 Science Products? | u.s. Geological Survey.” n.d. https://www.usgs.gov/faqs/how-do-i-use-scale-factor-landsat-level-2-science-products.\n\n\n“MODIS NDVI Slider.” n.d. https://khaledalshamaa.users.earthengine.app/view/modis-ndvi-slider.\n\n\nQu, Le’an, Zhenjie Chen, Manchun Li, Junjun Zhi, and Huiming Wang. 2021. “Accuracy Improvements to Pixel-Based and Object-Based LULC Classification with Auxiliary Datasets from Google Earth Engine.” Remote Sensing 13 (3): 453. https://doi.org/10.3390/rs13030453.\n\n\nZhang, Xunhe, Mojtaba Zeraatpisheh, Md Mizanur Rahman, Shujian Wang, and Ming Xu. 2021. “Texture Is Important in Improving the Accuracy of Mapping Photovoltaic Power Plants: A Case Study of Ningxia Autonomous Region, China.” Remote Sensing 13 (19): 3909. https://doi.org/10.3390/rs13193909."
  },
  {
    "objectID": "Week5.html#application-fig.1-workflow-of-practical-in-week-5",
    "href": "Week5.html#application-fig.1-workflow-of-practical-in-week-5",
    "title": "Week 5 Google Earth Engine I",
    "section": "Application {#Fig.1 Workflow of Practical in Week 5}",
    "text": "Application {#Fig.1 Workflow of Practical in Week 5}"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Amani, Meisam, Arsalan Ghorbanian, Seyed Ali Ahmadi, Mohammad Kakooei,\nArmin Moghimi, S. Mohammad Mirmazloumi, Sayyed Hamed Alizadeh Moghaddam,\net al. 2020. “Google Earth Engine Cloud Computing Platform for\nRemote Sensing Big Data Applications: A Comprehensive Review.”\nIEEE Journal of Selected Topics in Applied Earth Observations and\nRemote Sensing 13: 5326–50. https://doi.org/10.1109/JSTARS.2020.3021052.\n\n\nAmindin, Atiyeh, Soheila Pouyan, Hamid Reza Pourghasemi, Saleh Yousefi,\nand John P. Tiefenbacher. 2021. “Spatial and Temporal Analysis of\nUrban Heat Island Using Landsat Satellite Images.”\nEnvironmental Science and Pollution Research 28 (30): 41439–50.\nhttps://doi.org/10.1007/s11356-021-13693-0.\n\n\nblamannen. 2011. “Landsat Data Processing (in ENVI).” https://blamannen.wordpress.com/2011/05/01/landsat-data-processing-in-envi/.\n\n\nBrady, Maria. 2021. “Remote Sensing for Dummies.” https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d.\n\n\nBureau, US Census. n.d. “New York State Population Topped 20\nMillion in 2020.” https://www.census.gov/library/stories/state-by-state/new-york-population-change-between-census-decade.html.\n\n\nButcher, Ginger. 2016. Tour of the Electromagnetic Spectrum.\nThird edition. Washington, DC: National Aeronautics; Space\nAdministration.\n\n\nE. D. Chaves, Michel, Michelle C. A. Picoli, and Ieda D. Sanches. 2020.\n“Recent Applications of Landsat 8/OLI and Sentinel-2/MSI for Land\nUse and Land Cover Mapping: A Systematic Review.” Remote\nSensing 12 (18): 3062. https://doi.org/10.3390/rs12183062.\n\n\nEnvironment, U. N. 2021. “Beating the Heat: A Sustainable Cooling\nHandbook for Cities.” http://www.unep.org/resources/report/beating-heat-sustainable-cooling-handbook-cities.\n\n\nFrutuoso, Rui, Alexandre Lima, and Ana Cláudia Teodoro. 2021.\n“Application of Remote Sensing Data in Gold Exploration: Targeting\nHydrothermal Alteration Using Landsat 8 Imagery in Northern\nPortugal.” Arabian Journal of Geosciences 14 (6): 459.\nhttps://doi.org/10.1007/s12517-021-06786-0.\n\n\nFuleihan, Dean, Dominic Williams, and Daniel A Zarrilli. n.d. “THE\nCITY OF NEW YORK MAYOR BILL DE BLASIO.”\n\n\nGaertner, Philipp. n.d.a. “Europe Air Quality Winner.” https://gaertnerp.users.earthengine.app/view/europe-air-quality-winner#cloud=10;scale=15000;ranking=absolute%20difference%20(%CE%BCmol%2Fm%C2%B2);startdate=2020-03-01;enddate=2020-04-01;\n\n\n———. n.d.b. “Population-Rings.” https://gaertnerp.users.earthengine.app/view/population-rings.\n\n\nGaffin, S. R., C. Rosenzweig, R. Khanbilvardi, L. Parshall, S. Mahani,\nH. Glickman, R. Goldberg, R. Blake, R. B. Slosberg, and D. Hillel. 2008.\n“Variations in New York City’s Urban Heat Island\nStrength over Time and Space.” Theoretical and Applied\nClimatology 94 (1-2): 1–11. https://doi.org/10.1007/s00704-007-0368-3.\n\n\nGarcia, Mark. 2015. “Space Debris and Human Spacecraft.” http://www.nasa.gov/mission_pages/station/news/orbital_debris.html.\n\n\nGISGeography. 2015. “Passive Vs Active Sensors in Remote\nSensing.” https://gisgeography.com/passive-active-sensors-remote-sensing/.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth Engine:\nPlanetary-Scale Geospatial Analysis for Everyone.” Remote\nSensing of Environment 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHe, Yuanrong, Weiwei Ma, Zelong Ma, Wenjie Fu, Chihcheng Chen, Cheng-Fu\nYang, and Zhen Liu. 2019. “Using Unmanned Aerial Vehicle Remote\nSensing and a Monitoring Information System to Enhance the Management of\nUnauthorized Structures.” Applied Sciences 9 (22): 4954.\nhttps://doi.org/10.3390/app9224954.\n\n\nHemati, MohammadAli, Mahdi Hasanlou, Masoud Mahdianpari, and Fariba\nMohammadimanesh. 2021. “A Systematic Review of Landsat Data for\nChange Detection Applications: 50 Years of Monitoring the Earth.”\nRemote Sensing 13 (15): 2869. https://doi.org/10.3390/rs13152869.\n\n\n“How Do i Use a Scale Factor with Landsat Level-2 Science\nProducts? | u.s. Geological Survey.” n.d. https://www.usgs.gov/faqs/how-do-i-use-scale-factor-landsat-level-2-science-products.\n\n\nIndia Water Portal. 2012. “Remote Sensing Application in\nAgriculture & Forestry_dr Menon a r r\n(…,” December. https://www.slideshare.net/indiawaterportal/remote-sensing-application-in-agriculture-and-forestry-menon-a-r-r.\n\n\nJennifer, Vanos, Kalkstein Laurence, Sailor David, Shickman Kurt, and\nSheridan Scott. n.d. “Assessing the Health Impacts of Urban Heat\nIsland Reduction Strategies in the Cities of Baltimore, Los Angeles, and\nNew York.” https://www.adaptationclearinghouse.org/resources/assessing-the-health-impacts-of-urban-heat-island-reduction-strategies-in-the-cities-of-baltimore-los-angeles-and-new-york.html.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A\nRemote Sensing Perspective. Old Tappan: Pearson Education.\n\n\nLandsat Missions. n.d. “Landsat 7.” https://www.usgs.gov/landsat-missions/landsat-7.\n\n\nLlorens, Rafael, José Antonio Sobrino, Cristina Fernández, José M.\nFernández-Alonso, and José Antonio Vega. 2021. “A Methodology to\nEstimate Forest Fires Burned Areas and Burn Severity Degrees Using\nSentinel-2 Data. Application to the October 2017 Fires in the Iberian\nPeninsula.” International Journal of Applied Earth\nObservation and Geoinformation 95 (March): 102243. https://doi.org/10.1016/j.jag.2020.102243.\n\n\n“MODIS NDVI Slider.” n.d. https://khaledalshamaa.users.earthengine.app/view/modis-ndvi-slider.\n\n\nMullerova, Daniela, and Meredith Williams. 2019. “Satellite\nMonitoring of Thermal Performance in Smart Urban Designs.”\nRemote Sensing 11 (19): 2244. https://doi.org/10.3390/rs11192244.\n\n\n“NYC CoolRoofs.” n.d. https://www.c40.org/case-studies/nyc-coolroofs/.\n\n\nPeng, Jian, Qianyuan Liu, Zihan Xu, Danna Lyu, Yueyue Du, Ruilin Qiao,\nand Jiansheng Wu. 2020. “How to Effectively Mitigate Urban Heat\nIsland Effect? A Perspective of Waterbody Patch Size Threshold.”\nLandscape and Urban Planning 202 (October): 103873. https://doi.org/10.1016/j.landurbplan.2020.103873.\n\n\nPotapov, Peter, Matthew C. Hansen, Indrani Kommareddy, Anil Kommareddy,\nSvetlana Turubanova, Amy Pickens, Bernard Adusei, Alexandra Tyukavina,\nand Qing Ying. 2020. “Landsat Analysis Ready Data for Global Land\nCover and Land Cover Change Mapping.” Remote Sensing 12\n(3): 426. https://doi.org/10.3390/rs12030426.\n\n\nQu, Le’an, Zhenjie Chen, Manchun Li, Junjun Zhi, and Huiming Wang. 2021.\n“Accuracy Improvements to Pixel-Based and Object-Based LULC\nClassification with Auxiliary Datasets from Google Earth Engine.”\nRemote Sensing 13 (3): 453. https://doi.org/10.3390/rs13030453.\n\n\nRamos, Tiago B., Nádia Castanheira, Ana R. Oliveira, Ana Marta Paz,\nHanaa Darouich, Lucian Simionesei, Mohammad Farzamian, and Maria C.\nGonçalves. 2020. “Soil Salinity Assessment Using Vegetation\nIndices Derived from Sentinel-2 Multispectral Data. Application to\nLezíria Grande, Portugal.” Agricultural Water Management\n241 (November): 106387. https://doi.org/10.1016/j.agwat.2020.106387.\n\n\nSegarra, Joel, Maria Luisa Buchaillot, Jose Luis Araus, and Shawn C.\nKefauver. 2020. “Remote Sensing for Precision Agriculture:\nSentinel-2 Improved Features and Applications.” Agronomy\n10 (5): 641. https://doi.org/10.3390/agronomy10050641.\n\n\nShaker, Richard R., Yaron Altman, Chengbin Deng, Eric Vaz, and K.Wayne\nForsythe. 2019. “Investigating Urban Heat Island Through Spatial\nAnalysis of New York City Streetscapes.” Journal of Cleaner\nProduction 233 (October): 972–92. https://doi.org/10.1016/j.jclepro.2019.05.389.\n\n\nSurdu, C. M., C. R. Duguay, L. C. Brown, and D. Fernández Prieto. 2014.\n“Response of Ice Cover on Shallow Lakes of the North Slope of\nAlaska to Contemporary Climate Conditions (19502011): Radar\nRemote-Sensing and Numerical Modeling Data Analysis.” The\nCryosphere 8 (1): 167–80. https://doi.org/10.5194/tc-8-167-2014.\n\n\nXue, Wu, Peng Wang, and lingyu Zhong. 2021. “Geometric Correction\nof Optical Remote Sensing Satellite Images Captured by Linear Array\nSensors Circular Scanning Perpendicular to the Orbit.”\nChangchun: Chinese Academy of Sciences Vol.29 (12):\np.2924–2934. https://d-wanfangdata-com-cn.libproxy.ucl.ac.uk/periodical/ChlQZXJpb2RpY2FsQ0hJTmV3UzIwMjMwMTEyEg9neGptZ2MyMDIxMTIwMTcaCHBheDgxcGlx.\n\n\nYamamoto, Yoshika. 2006. “Measures to Mitigate Urban Heat\nIslands.”\n\n\nZhang, Jingcheng, Yanbo Huang, Ruiliang Pu, Pablo Gonzalez-Moreno, Lin\nYuan, Kaihua Wu, and Wenjiang Huang. 2019. “Monitoring Plant\nDiseases and Pests Through Remote Sensing Technology: A Review.”\nComputers and Electronics in Agriculture 165 (October): 104943.\nhttps://doi.org/10.1016/j.compag.2019.104943.\n\n\nZhang, Xunhe, Mojtaba Zeraatpisheh, Md Mizanur Rahman, Shujian Wang, and\nMing Xu. 2021. “Texture Is Important in Improving the Accuracy of\nMapping Photovoltaic Power Plants: A Case Study of Ningxia Autonomous\nRegion, China.” Remote Sensing 13 (19): 3909. https://doi.org/10.3390/rs13193909."
  },
  {
    "objectID": "Week6.html#summary",
    "href": "Week6.html#summary",
    "title": "6  Week6 Classification",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThe summary part of learning diary in this week has been divided by three parts, including how the classified data has been used in the previous research and real life, summary of classification methods, and summary of practical.\n\n6.1.1 Utilization of classified data\n\nAir pollution and land use and land cover\n\nImagery after classified can be used to monitor air pollution during a certain period. For example, based on Sentinel-3 imagery to collect and monitor sea and land surface temperature, and collect other data to analyze the potential factors affect the sea and land surface temperature. According to the classification results and relevant statistic graphs, it is clear to identify the changes of temperature between each time during the research period.\n\nLand use and land cover (urban green spaces)\n\nImagery collected by different sensors can be used for different procedures or analysis when analyzing issue related to urban green space. For example, we can choose medium spatial resolution imagery for decision making and modelling. Moreover, we can combine different sensors for urban garden mapping, counting urban trees, which will combine their strengths and optimize the results.\n\nMonitoring deforestation and illegal logging\nForest fire hazard mapping\n\nExpert systems is a system that answer the non-expert users’ queries based on the basic knowledge from an expert and give suitable advice back to the users. As machine learning, experts set training samples and test data to build a model for classification or prediction and give the classification or regression results back to users based on the data that users input.\nCommonly, we use classification and regression trees (CART), random forest, and other machine learning methods to classify imagery. When creating a decision tree (classification tree), we need to set a root and few decisions to split data into two sets. This process is not random, we need to modify the model with the lowest Gini impurity for each splitting time.\nFor building regression trees, we set the root of th regression tree and divide data based on sum of squared residuals, which we hope the value of SSR is the lowest within a certain neighborhood. In addition, we need to split data into training and testing data for each validation to avoid overfitting. To avoid overfitting, we can calculate Tree Score:\nTree Score = SSR + tree penalty(alpha) * T(number of leaves)\nSince we start with an ideal model, so that the start value of alpha is 0. Therefore, at the beginning, we will get the lowest tree score. Then, we need to divide data into training and testing data set several times (probably 10 times), build the model, and delete leaves to check whether the tree score and SSR change, until we get the lowest SSR expect for the tree score at the beginning, and return the corresponding alpha value to calculate tree score, and finish the modelling process.\n\n\n\n\n\n\nNote\n\n\n\n\nGini impurity = 1 - (probability of true)2 - (probability of false)2\nThe best sum of SSR value across all variables can be the root of regression tree\n20 pixels (or other units) is often the minimum number of pixels in a leaf\nDecision tree are not great for predicting with new data\n\n\n\nRandom forests, growing many classification decision tree, might solve the disadvantage of decision tree. Since random forest can be considered as the combination of many decision trees, so that the process of make final decision based on random forest is bootstrapping the complete data set into many data set, and each one will be divided for training and testing. Build decision trees based on different training and testing data sets and aggregate the results of the ensemble of trees.\n\n\n\n\n\n\nNote\n\n\n\n\nNumber of variables per tree is the square root of variables in the original data.\nThere might be out of bag error, which caused by all trees that did not have the rows in the original data and average prediction error.\n\n\n\n\n\n6.1.2 Remote sensing data classification methods\nImage classification is to turn pixels into different pre-defined categorical classes. There are two general types of classification based on pixels, including unsupervised classification, supervised classification. In this week’s lecture, we mentioned several types of supervised classification, including CART classification, random forest classification, and SVM, all of which are used to classify remote sensing images by first training some samples based on some features and then predicting the remaining pixels. This type of classification methods is currently very popular in the field of remote sensing because of its high accuracy rate. In the practical part, we try to implement CART decision tree and random forest in GEE for land cover classification in Shenzhen, China.\n\n\n6.1.3 Summary of practical\nThis week’s practical is mainly used to familiarize with the common remote sensing data classification methods in GEE. The main workflow of practical in this week shows in the following Figure 1. Our main project in this week includes Sentinel data pre-processing and classification based on the study area of Shenzhen, China.\n\n\n\nFig.1 Workflow of practical in Week 6\n\n\nAfter loading Sentinel-2 imagery and the Shenzhen boundary polygon, we found that there are clouds that cover the objects in several images that we collected based on the location, sensor, collecting period. Therefore, we have two methods to solve this question. One method is filter data again, based n the cloud level to filter images satisfy the condition of low cloud level, which means that the cloudy pixel percentages of each image should be lower than 1%. Figure 2 shows the result of dealing with clouds based on the first method. In Figure 2, the clouds are barely visible as an obstruction to the image.\n\n\n\nFig.2 Imagery after dealing with the cloud issue by using the first method\n\n\nThe other method is to mask the cloudy pixels and do division to decrease the impact of clouds on the subsequent processes and analyses. However, based on the imagery collected in this project, the second method did not work well. The clouds can still be seen clearly in Figure 3 below.\n\n\n\nFig.3 Imagery after dealing with the cloud issue by using the second method\n\n\nTo avoid the influence of clouds on the subsequent classification, I chose to take median value of each pixel from all images that I collected as the image which will be used to do classification later. The relevant code shows in the following code chunk:\nvar way_two_median = waytwo.reduce(ee.Reducer.median());\nvar vis_params = {\n  bands: ['B4_median', 'B3_median', 'B2_median'],\n  min: 0.0,\n  max: 0.3,\n};\nMap.addLayer(way_two_median, vis_params, 'True Color (432)');\nAfter clip the image based on the boundary of Shenzhen, I got the acceptable image without cloud issue within the boundary of Shenzhen, China (Figure 4). Then, we can move to do classification.\n\n\n\nFig.4 Image will be used for classification without cloud issue\n\n\nThere are three different classification methods used in this practical, including CART classification decision tree (Figure 5), random forest based on splitting polygons (Figure 6), and random forest based on splitting pixels (Figure 7). I create several polygons for 5 types of land use and land cover for training the models, including urban, water, grass, forest, and bare earth. The type of land use represented by the different colors can be distinguished according to the inspector. Light pink is urban, purple is water, light green is bare earth, dark pink is grass, and dark green is forest. The same color represents the same type of feature in all three classifications. Code used in GEE for do classification based on CART shows in the code chunk:\nvar classifier = ee.Classifier.smileCart().train({\n  features: training,\n  classProperty: classProperty,\n}); //build CART classifier based on the selected polygons and classes\nprint('CART, explained', classifier.explain());\nvar classified = waytwomedian_clip.classify(classifier); //apply the classifer\nMap.centerObject(shenzhen);\nMap.addLayer(classified, {min: 1, max: 5, palette: ['d99282', '466b9f', 'ab0000', 'dfdfc2', 'b3ac9f', '1c5f2c']}, \"classified\"); // output classification result\nMoreover, after comparing with the original image, I found that the result of this CART classification is not very accurate, for example, some parts of the water area with greenish color is classified as grass type. But the division between forest and urban is relatively accurate.\n\n\n\nFig.5 Classification result based on CART classification decision tree\n\n\nBased on the visual comparison of the original remote sensing images and the classification results in Figure 6, although no valid accuracy was obtained, it can be seen that the classification results by using random forest based on splitting polygons are relatively more accurate compared to the CART classification results. The lack of valid accuracy may be due to the fact that training and testing data sets were divided into polygons, so that there are not enough polygons.\n\n\n\nFig.6 Classification result by random forest based on splitting polygons\n\n\nThe difference between two random forest classification methods used in this practical is when I did random forest classification based on splitting pixels, it is needed to transform polygons that I created into pixels with corresponding class:\nvar pixel_number= 1000;\nvar urban_points=ee.FeatureCollection.randomPoints(urban, pixel_number).map(function(i){\n  return i.set({'class': 1})})\nvar water_points=ee.FeatureCollection.randomPoints(water, pixel_number).map(function(i){\n  return i.set({'class': 2})})\nvar grass_points=ee.FeatureCollection.randomPoints(grass, pixel_number).map(function(i){\n  return i.set({'class': 3})})\nvar bare_earth_points=ee.FeatureCollection.randomPoints(bare_earth, pixel_number).map(function(i){\n  return i.set({'class': 4})})\nvar forest_points=ee.FeatureCollection.randomPoints(forest, pixel_number).map(function(i){\n  return i.set({'class': 5})})\nFrom Figure 7 below, we can visualize the validation error matrix, validation overall accuracy, and validation customer accuracy, and the accuracy of the latter two is very high, indicating that the model built based on splitting-pixel random forest is very accurate in classification.\n\n\n\nFig.7 Classification result by random forest based on splitting pixel with overall accuracy and customer accuracy\n\n\nTherefore, based on the above three classification results, it may be more appropriate for this practical to use random forest based on splitting pixels to classify the acquired Sentinel-2 images in the range of Shenzhen.\n\n\n\n\n\n\nQuestions\n\n\n\n\nThe proportion of training and testing data set might be different from DS course?\nWill data leakage happen when doing CART classification by using training data to generate classifier to classify the whole image?\nWhy we need QA and why we set “qa60”?"
  },
  {
    "objectID": "Week6.html#application",
    "href": "Week6.html#application",
    "title": "6  Week6 Classification",
    "section": "6.2 Application",
    "text": "6.2 Application\nClassification of remote sensing images is vital in many studies which need satellite image information (Dhingra and Kumar 2019; Zhang et al. 2021), and with the continuous development of technology, there are more and more methods of classification, enabling more accurate classification results of remote sensing images applicable to different situations. Based on the classification methods covered in this week’s lecture and practical, I have found relevant literature to add to the application of those classification methods. In addition, I also add several applications of other classification methods that are currently more common. Since the choice of classification method will largely affect the performance of the classification (Zhang et al. 2021), it is important to understand and be familiar with the characteristics of different classification methods and the applicable scenarios.\n\nApplications of CART classification\n\nLi et al. (2023) used, NDVI, EVI, NDWI, NDMRI, and the radar back scattering coefficient to train the samples and build a CART decision tree to classify the acquired Gaofen satellite images for land cover in Xinjiang, China, and obtained a high accuracy. Although, I think this method can get relatively high accurate land cover classification results, in order to ensure high accuracy, the CART decision tree that the authors established requires very detailed conditions. Therefore, the robustness and universal applicability are relatively low, and this CART decision tree almost cannot directly used for land cover classification in the Gaofen image in different time of the same area.\n\nApplications of random forest classification\n\nSupervised classification based on random forest can avoid overfitting and also be more robust (Zhang et al. 2021).\nPelletier et al. (2016) used random forest and SVM classification methods to classify the land use classes in based on SPOT-4 and Landsat 8 imagery and compare the results and accuracy. They divided the land use types in the study area into 18 categories, such as wheat, sunflower, etc., and compared the ability of different classification methods to identify different types of features by calculating user’s accuracy, producer’s accuracy, and F-Score (Pelletier et al. 2016). In this study, the researchers are trying to determine whether random forest-based classification is feasible for a large study area by comparing the accuracy of random forest classification to that of the more traditional SVM classification method.\nThe comparison method they chose to determine whether random forest classification is feasible may be rather one-sided, and one can try to select several different types of study areas to try random forest classification and compare the accuracy. Moreover, in this study, the authors chose a predetermined land use type that is more plant-oriented, and the selected categories should be appropriately adjusted to compare the ability of this classification method to discriminate between different types of features.\nIn addition, (Zhang et al. 2021) classified the land cover types in Beijing based on Sentinel-2 images and random forest with Bayesian Optimization, which is also worth to study and think about.\n\nApplications of other classification methods\n\nSupervised classification classify the images based on the training samples that users selected, which means that users need to define number of classes and create representative features of each class in advance (Dhingra and Kumar 2019). Supervised classification is used to provide land use and land cover classes (Dhingra and Kumar 2019). The common methods are maximum likelihood classification, less distance classification, Support Vector Machine (SVM) (Dhingra and Kumar 2019).\nIn addition, unsupervised classification is to classify the images into different categories based on different spectra and requires the user to merge the classified results into the desired categories (Dhingra and Kumar 2019). The most obvious difference between unsupervised classification and supervised classification is that the former does not require the selection of a training sample (Dhingra and Kumar 2019).\nObject-based classification is also useful in remote sensing studies, which will elaborate in next week."
  },
  {
    "objectID": "Week6.html#reflection",
    "href": "Week6.html#reflection",
    "title": "6  Week6 Classification",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis week I learned several supervised classification methods that I had not been exposed to in my undergraduate studies, including CART, random forest classification, and SVM, and implemented a preliminary implementation of land cover classification in GEE using the above methods. I also learned about several more optimal classification methods based on random forest classifier by reading the literature. I think it is very useful and interesting to learn and apply different classification methods. The usefulness lies in the fact that similar methods can be used in future research to improve the accuracy of the classification, not only to review the relevant content in the data science course, but also to understand the essential principles of these classification methods. The interesting part is that different classification methods will give different classification results, and even though the principles are similar, the classification results will be quite different.\nI think several remote sensing image classification methods that I learned and understand during this week will be very useful for my future research. For example, if I want to study the change of land use types in London to determine whether there are illegal buildings privately occupying public areas, I need to compare the change of land use types in the same area before and after a period of time, but there are high requirements for the resolution of the images and the accuracy of the classification. Although I may adjust my random forest classifier for image classification according to the actual research problem and the characteristics of the study area to make the accuracy of image classification higher, the essence is still based on random forest-like method for image classification.\n\n\n\n\nDhingra, Sakshi, and Dharminder Kumar. 2019. “A Review of Remotely Sensed Satellite Image Classification.” International Journal of Electrical and Computer Engineering (IJECE) 9 (3): 1720. https://doi.org/10.11591/ijece.v9i3.pp1720-1731.\n\n\nLi, Chunyu, Rong Cai, Wei Tian, Junna Yuan, and Xiaofei Mi. 2023. “Land Cover Classification by Gaofen Satellite Images Based on CART Algorithm in Yuli County, Xinjiang, China.” Sustainability 15 (3): 2535. https://doi.org/10.3390/su15032535.\n\n\nPelletier, Charlotte, Silvia Valero, Jordi Inglada, Nicolas Champion, and Gérard Dedieu. 2016. “Assessing the Robustness of Random Forests to Map Land Cover with High Resolution Satellite Image Time Series over Large Areas.” Remote Sensing of Environment 187 (December): 156–68. https://doi.org/10.1016/j.rse.2016.10.010.\n\n\nZhang, Xunhe, Mojtaba Zeraatpisheh, Md Mizanur Rahman, Shujian Wang, and Ming Xu. 2021. “Texture Is Important in Improving the Accuracy of Mapping Photovoltaic Power Plants: A Case Study of Ningxia Autonomous Region, China.” Remote Sensing 13 (19): 3909. https://doi.org/10.3390/rs13193909."
  },
  {
    "objectID": "Week8.html#summary",
    "href": "Week8.html#summary",
    "title": "8  Week 8 Temperature and policy",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Summary of lecture\n\nTemperature and policy\nUrban heat island is a serious issue refers to the urban areas obtain relatively higher atmospheric and surface temperatures than surrounding areas. Based on the previous research, people found that the potential factors caused or exacerbated UHI effect include dark surfaces retain solar radiation, less vegetation, low Sky View Factor (SVF), cloud cover, building material types, and other aspects.\nThe impact of UHI on humans, society, and the environment is significant. Therefore, there are many policies, either global or proposed by national and local governments to mitigate the negative effects of the urban heat island effect. Some of the more representative measures mentioned in the policies to mitigate the urban heat island effect include superblocks (???), Medellín Green Corridors (restore green corridors along roads and waterways), Sydney’s western suburbs (???).\nExtracting temperature from satellite data\n\n\n\n8.1.2 Summary of practical\n\n\n8.1.3 Question"
  },
  {
    "objectID": "Week8.html#application",
    "href": "Week8.html#application",
    "title": "8  Week 8 Temperature and policy",
    "section": "8.2 Application",
    "text": "8.2 Application"
  },
  {
    "objectID": "Week8.html#reflection",
    "href": "Week8.html#reflection",
    "title": "8  Week 8 Temperature and policy",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection"
  }
]