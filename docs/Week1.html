<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CASA0023 Learning Diary - 1&nbsp; Week 1 Getting started with remote sensing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Week2.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Week 1 Getting started with remote sensing</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CASA0023 Learning Diary</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Content</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">Introduction</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week1.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Week 1 Getting started with remote sensing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Week 2 Portfolio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Week 3 Corrections</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Week 4 Policy</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week 5 Google Earth Engine I</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week6.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week6 Classification</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week7.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week 7 Classification II</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week8.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Week 8 Temperature and policy</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week9.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Week 9 SAR in GEE</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">Summary</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="toc-section-number">1.1</span>  Summary</a>
  <ul class="collapse">
  <li><a href="#summary-of-lecture" id="toc-summary-of-lecture" class="nav-link" data-scroll-target="#summary-of-lecture"><span class="toc-section-number">1.1.1</span>  Summary of lecture</a></li>
  <li><a href="#summary-of-practical" id="toc-summary-of-practical" class="nav-link" data-scroll-target="#summary-of-practical"><span class="toc-section-number">1.1.2</span>  Summary of practical</a></li>
  </ul></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application"><span class="toc-section-number">1.2</span>  Application</a>
  <ul class="collapse">
  <li><a href="#passive-remote-sensing-application" id="toc-passive-remote-sensing-application" class="nav-link" data-scroll-target="#passive-remote-sensing-application"><span class="toc-section-number">1.2.1</span>  Passive remote sensing application</a></li>
  <li><a href="#active-remote-sensing-application" id="toc-active-remote-sensing-application" class="nav-link" data-scroll-target="#active-remote-sensing-application"><span class="toc-section-number">1.2.2</span>  Active remote sensing application</a></li>
  </ul></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="toc-section-number">1.3</span>  Reflection</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Week 1 Getting started with remote sensing</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In this week, we focused on presenting the concept of remote sensing and introducing the basics terms related to remote sensing.</p>
<section id="summary" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">1.1</span> Summary</h2>
<p>Remote sensing was first created for military and warfare purposes, but is now also used in a wide range of civilian applications <span class="citation" data-cites="brady2021">(<a href="references.html#ref-brady2021" role="doc-biblioref">Brady 2021</a>)</span>.</p>
<section id="summary-of-lecture" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="summary-of-lecture"><span class="header-section-number">1.1.1</span> Summary of lecture</h3>
<p>In fact, in our real life, applications for remote sensing are relatively common and there are a large number of satellites currently in use <span class="citation" data-cites="garcia2015">(<a href="references.html#ref-garcia2015" role="doc-biblioref">Garcia 2015</a>)</span>.</p>
<p>Remote sensing can be generally divided into two types based on different types of sensors, one is passive sensor, the other is active sensor. Passive sensor usually does not emit anything, it just reflects energy (electromagnetic waves) from the sun, for instance, satellite sensor. Active sensor emits electromagnetic waves actively and receive the energy back, such as Radar and LIDAR. The following picture shows the difference between passive remote sensing and active remote sensing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d"><img src="week1_passive_active_RS.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Fig.1 Schematic diagram of the principles of active and passive remote sensing. Source:</figcaption><p></p>
</figure>
</div>
<p>There is a term called radiation budget, which consists of four components, including energy entering, reflected, absorbed, and emitted by the Earth system , and is mainly used to evaluate the degree to which energy is balanced through the more complex processes of propagation, absorption, and reflection <span class="citation" data-cites="butcher2016">(<a href="references.html#ref-butcher2016" role="doc-biblioref">Butcher 2016</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week1_radiation_budget.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Fig.2 Radiation budget. Source: <span class="citation" data-cites="butcher2016">Butcher (<a href="references.html#ref-butcher2016" role="doc-biblioref">2016</a>)</span></figcaption><p></p>
</figure>
</div>
<p>Therefore, electromagnetic radiation (EMR) from the sun is different with the energy arrive the earth surface, since the energy can be scatter by the atmosphere. Atmosphere scatter can be divided into three types, including Rayleigh, Mie and non selective, which is depends on the sizes of particles and the wavelengths.</p>
<p>These scattering phenomena are also very common in everyday life, for instance, the sky is blue is because Raleigh scattering happens. Similarly, we can explain the black sky in the space and blue ocean. Remote sensing is based on the identification of different types of features through the unique spectral signatures formed by the different reflections and absorptions of features in response to EMR <span class="citation" data-cites="brady2021">(<a href="references.html#ref-brady2021" role="doc-biblioref">Brady 2021</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week1_Spectral curves of characteristic features.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Fig.3 Spectral curves of characteristic features. Source: <span class="citation" data-cites="butcher2016">Butcher (<a href="references.html#ref-butcher2016" role="doc-biblioref">2016</a>)</span></figcaption><p></p>
</figure>
</div>
<p>However, passive remote sensing has a very large disadvantage that the quality of imagery depends on the weather and cloud cover. We can solve this problem by using active sensors, for instance, Synthetic Aperture Radar (SAR), which can see through clouds, volcanic ash, and other bad atmospheric conditions based on longer wavelengths.</p>
<p>Remote sensing imagery is raster data, but there are a variety of data storage formats, including band interleaved by line, band sequential, band interleaved by pixel, and GeoTIFF.</p>
<p>There are four resolutions to describe the quality or characteristics of the imagery, including spatial resolution (size of raster cells), spectral resolution (define the shortest wavelength intervals), temporal resolution (revisit time), and radiometric resolution (the ability to detect the smallest differences in energy, or the sensitivity of the sensor).</p>
<p>About the orbits of the sensors, there are geosynchronous obits and geostationary orbits.</p>
<p><strong><em>Advantages and Disadvantages of remote sensing <span class="citation" data-cites="jensen2015">Jensen (<a href="references.html#ref-jensen2015" role="doc-biblioref">2015</a>)</span></em></strong></p>
<p>Notice:</p>
<ol type="1">
<li>The direction of sunlight might influences the image, and may even affect the interpretation of the images.</li>
<li>Spectral signatures can be discrete and continuous.</li>
</ol>
</section>
<section id="summary-of-practical" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="summary-of-practical"><span class="header-section-number">1.1.2</span> Summary of practical</h3>
<p>The practical part of this week mainly focus on using QGIS and SNAP two software to get familiar with remote sensing satellite images and preliminarily understand the supervised classification of images, and intuitively understand the difference of land use in the study area and the difference of spectral characteristics of different land use types through statistical maps. This is very important for the next few weeks of study. Although I may not rely too much on software such as SNAP to process and analyze remote sensing images, it can help me understand the meaning of corresponding R codes and the content in the course. Following Figure 4 is the overall workflow of the practical in this week.</p>
<div class="quarto-figure quarto-figure-center" style="float: center">
<figure class="figure">
<p><img src="week1_practical_workflow.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Fig.4 Workflow of Practical in Week1</figcaption><p></p>
</figure>
</div>
<p>The first main session is that I downloaded Sentinel-2 data from Copernicus Open Access Hub website based on several criteria and loaded data into QGIS first to try to use familiar software (QGIS) to get familiar with the academic terms we learnt in the lecture, including true color satellite image, spectral signature, and raster stack. I also did down-scaling and up-scaling based on QGIS resampling tool to make all the bands that I collected are with the same resolution (image enhancement) before subsequent process and analysis.</p>
<p>The second main section is create Tasseled Cap within the study area after mask and resample the imagery to get three more bands, including brightness, greenness, and wetness. The process of generating Tasseled Cap is a process to transform original data into a new data set with reducing the dimensions and maximizing the variance. Based on the different values of brightness, greenness and wetness correspond to different degrees of brightness, greenness and wetness, which can provide a preliminary understanding of land use types in the study area. Light areas in brightness image (Figure 5) should be bare soil, man-made surface, or areas covered by other bright materials. In the greenness image (Figure 6), green vegetation, such as forest, grassland and crops, can be clearly distinguished. In the wetness image (Figure 7), I can mainly distinguish the place with high moisture, such as pond, lake, and river.</p>
<p>Three components of Tasseled Cap formulas based on Sentinel imagery:</p>
<p><span class="math inline">\(Brightness = 0.3037(B2)+0.2793(B3)+0.4743(B4)+0.5585(B8)+0.5082(B11)+0.1863(B12)\)</span></p>
<p><span class="math inline">\(Greenness = -0.2848(B2)-0.2435(B3)-0.5436(B4)+0.7243(B8)+0.0840(B11)-0.1800(B12)\)</span></p>
<p><span class="math inline">\(Wetness = 0.1509(B2)+0.1973(B3)+0.3279(B4)+0.3406(B8)-0.7112(B11)-0.45(B12)\)</span></p>
<p>Fig.5</p>
<p>Fig.6</p>
<p>Fig.7</p>
<p>The third section in this practical is creating five types of land use sample polygons shared by Landsat and Sentinel images were selected, including urban, water body, grassland, forest and bare soil, and export the drawn polygons and remote sensing images after mask and resampling to R studio. After that, I created two graphs show the mean and standard deviation of 5 types of POIs vs.&nbsp;band values of both Sentinel-2 and Landsat imagery, and two graphs are the density plots for the distributions of 5 types of land use with different band values of both Sentinel-2 and Landsat imagery. The mean and standard deviation of five types of land use pixels selected in study area vs.&nbsp;band values plot and density of different categories of land use pixels selected in the study area vs.&nbsp;band values graph of Sentinel-2 imagery show in the following Figure 8, and similar plots of Landsat-8 imagery show in Figure 9 below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week1_sen_ABplots.png" class="img-fluid figure-img" width="700"></p>
<p></p><figcaption class="figure-caption">Fig.8 Mean and standard deviation of five types of land uses (A) and density plot (B) in the selected Sentinel-2</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week1_lan_ABplots.png" class="img-fluid figure-img" width="700"></p>
<p></p><figcaption class="figure-caption">Fig.9 Mean and standard deviation of five types of land uses (A) and density plot (B) in the selected Landsat-8 imagery</figcaption><p></p>
</figure>
</div>
<p>As can be seen from Figure A in Figure 8 and 9 above, when green vegetation, such as grassland and forest, is extracted from remote sensing images, red band and near infrared band can be mainly used, because there is a significant difference in pixel values between them and other bands. This feature is universally applicable to Sentinel-2 and Landsat-8 images. In addition, it can be seen from Figure B in FIG. 8 and FIG. 9 that water bodies are concentrated in a relatively small band value, while other land use types are not highly concentrated in a relatively narrow band range. This feature allows us to extract water from images with high accuracy.</p>
<p>There are some practical limitations. First of all, different research areas, time and other conditions correspond to different images. Some areas may not have rich land use types, or the contrast of land use types is not obvious, which may result in a low difference in results. In addition to different sensors, the differences in FIG. 8 and FIG. 9 May also result from different time of image acquisition, resulting in differences in spectral features of the same ground objects acquired. In addition, when SNAP creates polygons representing the five land use types, it may not be enough or representative enough, so that the results in Figure 8 and 9 May not fully meet the general applicability, but the general trend of change is similar.</p>
<div class="callout-important callout callout-style-simple callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Notice
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>SNAP is another GIS software specific to Sentinel, which can be access to resampling, reproject, masking, classifying, PCA, and many other processing and analyzing methods.</li>
<li>Before the subsequent process after load the data into R Studio, it is needed to unify the coordinate systems of the two images.</li>
<li>Vector data need to be converted into SpatVector in R.</li>
</ol>
</div>
</div>
<div class="callout-note callout callout-style-simple callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Questions
</div>
</div>
<div class="callout-body-container callout-body">
<p>1. Why when TCI values are coded between 0 and 255 and radiometric resolution of Sentinel-2 is 12-bit means brightness levels from 0 and 4095 cannot be clear how this product has been made?</p>
</div>
</div>
</section>
</section>
<section id="application" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="application"><span class="header-section-number">1.2</span> Application</h2>
<section id="passive-remote-sensing-application" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="passive-remote-sensing-application"><span class="header-section-number">1.2.1</span> Passive remote sensing application</h3>
<p>There are many examples of passive remote sensing applications. For example, the near-infrared (NIR) band is important for passive remote sensing. The NIR band can be used in applications such as monitoring vegetation growth, crop pests and diseases <span class="citation" data-cites="butcher2016">(<a href="references.html#ref-butcher2016" role="doc-biblioref">Butcher 2016</a>)</span>. The main reason for this is that healthy vegetation absorbs red and blue light to synthesise chlorophyll, and the more chlorophyll is synthesised, the stronger the NIR reflection <span class="citation" data-cites="butcher2016">(<a href="references.html#ref-butcher2016" role="doc-biblioref">Butcher 2016</a>)</span>. In addition, <span class="citation" data-cites="ramos2020">Ramos et al. (<a href="references.html#ref-ramos2020" role="doc-biblioref">2020</a>)</span> assessed soil salinity in Portugal based on vegetation indices computed from Sentinel-2 images.</p>
<p>In this learning diary, I will mainly summarize some examples of passive remote sensing applications based on Landsat and Sentinel series satellite imagery. Medium-resolution images like Landsat 8 and Sentinel-2 are more representative of the interactions between human and nature, and are more commonly used in studies targeting passive remote sensing because of the short revisit period of both satellites and the data are free <span class="citation" data-cites="e.d.chaves2020">(<a href="references.html#ref-e.d.chaves2020" role="doc-biblioref">E. D. Chaves, C. A. Picoli, and D. Sanches 2020</a>)</span>. Below are two relatively typical, specific examples of applying Sentinel-2 and Landsat 8 satellite imagery.</p>
<section id="application-based-on-sentinel-data" class="level4" data-number="1.2.1.1">
<h4 data-number="1.2.1.1" class="anchored" data-anchor-id="application-based-on-sentinel-data"><span class="header-section-number">1.2.1.1</span> Application based on Sentinel data</h4>
<p><span class="citation" data-cites="llorens2021">Llorens et al. (<a href="references.html#ref-llorens2021" role="doc-biblioref">2021</a>)</span> explored a method for simulating the area burned and the extent of forest damage following a forest fire on the border between Spain and northern Portugal, based on Sentinel-2 level 2A data. By comparing the spectral profiles of remote sensing images of this forest before and after the forest fire, <span class="citation" data-cites="llorens2021">Llorens et al. (<a href="references.html#ref-llorens2021" role="doc-biblioref">2021</a>)</span> found that reflections in the green and near-infrared bands decreased significantly after the fire, while reflections in the short-wave infrared band increased more significantly. Therefore, <span class="citation" data-cites="llorens2021">Llorens et al. (<a href="references.html#ref-llorens2021" role="doc-biblioref">2021</a>)</span> created Normalized Burn Ratio (NBR) and differenced NBR (dNBR) parameters to identify the surface of the fire and the severity of the burn. Finally, they concluded that this method is accepted for determine burn area and damage after forest fire. The authors chose to use Sentinel-2 data might because the high spatial resolution and short revisit time with low cloud cover and the data must be obtained as close as possible to the period of the forest fire.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week1_Sen_application_1.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Fig.6 Sentinel-2 dNBR image and simulation dNBR in EFFIS image. Source: <span class="citation" data-cites="llorens2021">Llorens et al. (<a href="references.html#ref-llorens2021" role="doc-biblioref">2021</a>)</span></figcaption><p></p>
</figure>
</div>
<p>In my opinions, based on their comparison of the simulated results with actual GPS data and more accurate remote sensing data, the dNBR coefficients calculated by Sentinel-2 are more accurate when applied to EFFIS data for the assessment of burn severity level after forest fires. Since Sentine-2 data has 4 more bands in the Red Edge spectral region <span class="citation" data-cites="segarra2020">(<a href="references.html#ref-segarra2020" role="doc-biblioref">Segarra et al. 2020</a>)</span>, I deem that the authors chose the relatively suitable data and methods as well. However, this method has only been applied to this one scenario and has not been applied to other forests in different situations, so it is not very rigorous to conclude that this method is accurate.</p>
</section>
<section id="application-based-on-landsat-data" class="level4" data-number="1.2.1.2">
<h4 data-number="1.2.1.2" class="anchored" data-anchor-id="application-based-on-landsat-data"><span class="header-section-number">1.2.1.2</span> Application based on Landsat data</h4>
<p>As the Landsat series of satellites evolved from generation to generation to Landsat 8, the spatial resolution of 30m was still retained, but the quantization was enhanced by carrying two sensors, OLI and TIRS <span class="citation" data-cites="hemati2021">(<a href="references.html#ref-hemati2021" role="doc-biblioref">Hemati et al. 2021</a>)</span>. In recent years, Landsat imagery has been widely used because of the thermal infrared band, which is applied to mine exploration and predicting mineral production <span class="citation" data-cites="frutuoso2021">(<a href="references.html#ref-frutuoso2021" role="doc-biblioref">Frutuoso, Lima, and Teodoro 2021</a>)</span>; and because the Landsat series of satellites collects remote sensing images uninterruptedly since the first satellite was launched in 1972 until 2023, Landsat imagery can be applied to long-term studies of land use and land cover type changes <span class="citation" data-cites="potapov2020">(<a href="references.html#ref-potapov2020" role="doc-biblioref">Potapov et al. 2020</a>)</span>.</p>
<p>With the rapid growth of cities around the world, the urban heat island effect is also increasing, and the average land surface temperature continues to grow <span class="citation" data-cites="amindin2021">(<a href="references.html#ref-amindin2021" role="doc-biblioref">Amindin et al. 2021</a>)</span>. <span class="citation" data-cites="amindin2021">Amindin et al. (<a href="references.html#ref-amindin2021" role="doc-biblioref">2021</a>)</span> used Landsat 4, 5, 7, 8 images to compute land surface temperature, urban thermal field variance index and urban heat island index to investigate the intensity of urban heat island effect in Ahvaz, Iran and the change of distribution from 1995 to 2016. <span class="citation" data-cites="amindin2021">Amindin et al. (<a href="references.html#ref-amindin2021" role="doc-biblioref">2021</a>)</span> finally found that the green area decreased by 50% and the area with high surface temperature expanded during this 21-year period.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week1_Lan_application1.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Fig.7 Composite map of UTFVI and UHI index of Ahvaz. Source: <span class="citation" data-cites="amindin2021">Amindin et al. (<a href="references.html#ref-amindin2021" role="doc-biblioref">2021</a>)</span></figcaption><p></p>
</figure>
</div>
<p>I think their data selection is reasonable, because they need data with a large time span for analysis, and Landsat series data can meet this requirement, and the spatial resolution of Landsat 4, 5, 7, 8 images selected by the authors is 30m and they can both be used directly to calculate the LST, which can simplify the task of data processing part. In terms of analysis, they used support vector machine method for land use classification and quantified the impact of urban heat island effect by two parameters (UHI and UTFVI). Based on its land use classification accuracy (93%) and the comparison of the LST distribution and the plots combining UHI and UTFVI together, the feasibility, reproducibility, and accuracy of these methods are relatively high. However, other land use classification methods can also be tried to improve the accuracy of the classification.</p>
</section>
</section>
<section id="active-remote-sensing-application" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="active-remote-sensing-application"><span class="header-section-number">1.2.2</span> Active remote sensing application</h3>
<p>The quality of passive remote sensing images may be negatively affected by receiving weather effects, while active remote sensing avoids this problem and can collect images day and night because electromagnetic radiation emitted by the sun is not required. Therefore its applications are also very wide <span class="citation" data-cites="gisgeography2015">(<a href="references.html#ref-gisgeography2015" role="doc-biblioref">GISGeography 2015</a>)</span>.</p>
<p><span class="citation" data-cites="zhang2019">Zhang et al. (<a href="references.html#ref-zhang2019" role="doc-biblioref">2019</a>)</span> used SAR and LIDAR data to capture changes in crops due to pests and diseases, and they also compared the use of visible and near-infrared bands in remote sensing imagery to monitor crop pests and diseases, but the point of using SAR and LIDAR data is to monitor pests and diseases that tend to breed in wet and cloudy weather, or crop morphology that is susceptible to changes due to pests and diseases. I think this approach has a great advantage because the data obtained is of high resolution and can be used to monitor very small changes without being affected by weather conditions.</p>
<p><span class="citation" data-cites="he2019">He et al. (<a href="references.html#ref-he2019" role="doc-biblioref">2019</a>)</span> monitored the illegal buildings based on the high-resolution unmanned aerial vehicle (UAV) remote sensing images and the acquired SAR data, and build 3D models for the illegal buildings in ArcGIS for further judgment. I think this method can find the illegal building more accurately and determine whether the illegal building has been demolished according to the regulations. In addition, the UAV remote sensing images can acquire data at any time according to the research needs. However, UAV remote sensing is less efficient in acquiring data and is not suitable for situations where the study area is large. It is also necessary to bear all the costs associated with the UAV and to master the UAV piloting skills. Therefore, the reproducibility of the method may not be high.</p>
<p><span class="citation" data-cites="surdu2014">Surdu et al. (<a href="references.html#ref-surdu2014" role="doc-biblioref">2014</a>)</span> collected a total of 78 SAR data from 1991 to 2011 to monitor the changes in floating ice coverage, thickness and grounded ice. <span class="citation" data-cites="surdu2014">Surdu et al. (<a href="references.html#ref-surdu2014" role="doc-biblioref">2014</a>)</span> found that there is an increasing trend of floating ice and a decreasing trend of grounded ice. In addition, there is an increasing trend in the number or quantity of lakes that maintain liquid water under floating ice, and the ice cover thins in winter <span class="citation" data-cites="surdu2014">(<a href="references.html#ref-surdu2014" role="doc-biblioref">Surdu et al. 2014</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week1_SAR_application_1.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Fig.8 Floating ice and grounded ice change from 1991 to 2011 in Arctic shallow lakes. Source: <span class="citation" data-cites="surdu2014">Surdu et al. (<a href="references.html#ref-surdu2014" role="doc-biblioref">2014</a>)</span></figcaption><p></p>
</figure>
</div>
<p>I deem that the data they chose is more appropriate, and since it needs to go through thick ice, maybe radar data is more appropriate than remote sensing images. Secondly, they chose the date of the radar data, and almost chose the data from the period when the data quality was high and the ice was the thickest. However, since this study is relatively early, there are not yet many high-precision remote sensing images available to assist their study, so perhaps trying to incorporate high-resolution remote sensing images may help improve the accuracy of the study if newer techniques can be combined.</p>
</section>
</section>
<section id="reflection" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">1.3</span> Reflection</h2>
<p>What is interesting?</p>
<p>I think the idea of taking pictures of the Earth from a distance was a very novel idea in the 1960s, and remote sensing has evolved to the point where there are several series of satellites, different uses of satellites, and even vehicle-mounted devices, drones and other devices that can be used as tools to access remote sensing data. In addition, software for processing remote sensing data has become increasingly available.</p>
<p>After learning about the characteristic spectral curves of features, I found it interesting that the spectral curves of grasslands and forests can be significantly different even if they do not look very different to the human eye on remote sensing images. And while the spectral curves of forests formed by different types of trees may not be identical, the trends are very similar.</p>
<p>What is useful in the future?</p>
<p>After understanding the basics of remote sensing and examples of research using different remote sensing techniques and data, I have a deeper understanding of the characteristics of Landsat and Sentinel satellite data, which will help me a lot in choosing the right data when doing related research in the future. In addition, by looking up literature and understanding the application of remote sensing techniques in practical research, it was useful for me to understand the content in class, expand my horizon, and choose a topic for my thesis.</p>
<p>If the opportunity arises, I may in the future investigate the combination of agent-based modelling and remote sensing to explore the impact of forest fires and in this way quantify the negative impact of forest fires.</p>
<p>What is not useful? (can be instead)</p>
<p>I think what I have learned so far this week has been useful because as learning and understanding remote sensing as a technology requires introducing conceptual knowledge first, rather than exploring an aspect in depth. However, remote sensing images are easily affected by weather, such as cloud cover, and the steps and principles of pre-processing remote sensing images can be introduced first, before introducing active remote sensing may be more complete.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-amindin2021" class="csl-entry" role="doc-biblioentry">
Amindin, Atiyeh, Soheila Pouyan, Hamid Reza Pourghasemi, Saleh Yousefi, and John P. Tiefenbacher. 2021. <span>“Spatial and Temporal Analysis of Urban Heat Island Using Landsat Satellite Images.”</span> <em>Environmental Science and Pollution Research</em> 28 (30): 41439–50. <a href="https://doi.org/10.1007/s11356-021-13693-0">https://doi.org/10.1007/s11356-021-13693-0</a>.
</div>
<div id="ref-brady2021" class="csl-entry" role="doc-biblioentry">
Brady, Maria. 2021. <span>“Remote Sensing for Dummies.”</span> <a href="https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d">https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d</a>.
</div>
<div id="ref-butcher2016" class="csl-entry" role="doc-biblioentry">
Butcher, Ginger. 2016. <em>Tour of the Electromagnetic Spectrum</em>. Third edition. Washington, DC: National Aeronautics; Space Administration.
</div>
<div id="ref-e.d.chaves2020" class="csl-entry" role="doc-biblioentry">
E. D. Chaves, Michel, Michelle C. A. Picoli, and Ieda D. Sanches. 2020. <span>“Recent Applications of Landsat 8/OLI and Sentinel-2/MSI for Land Use and Land Cover Mapping: A Systematic Review.”</span> <em>Remote Sensing</em> 12 (18): 3062. <a href="https://doi.org/10.3390/rs12183062">https://doi.org/10.3390/rs12183062</a>.
</div>
<div id="ref-frutuoso2021" class="csl-entry" role="doc-biblioentry">
Frutuoso, Rui, Alexandre Lima, and Ana Cláudia Teodoro. 2021. <span>“Application of Remote Sensing Data in Gold Exploration: Targeting Hydrothermal Alteration Using Landsat 8 Imagery in Northern Portugal.”</span> <em>Arabian Journal of Geosciences</em> 14 (6): 459. <a href="https://doi.org/10.1007/s12517-021-06786-0">https://doi.org/10.1007/s12517-021-06786-0</a>.
</div>
<div id="ref-garcia2015" class="csl-entry" role="doc-biblioentry">
Garcia, Mark. 2015. <span>“Space Debris and Human Spacecraft.”</span> <a href="http://www.nasa.gov/mission_pages/station/news/orbital_debris.html">http://www.nasa.gov/mission_pages/station/news/orbital_debris.html</a>.
</div>
<div id="ref-gisgeography2015" class="csl-entry" role="doc-biblioentry">
GISGeography. 2015. <span>“Passive Vs Active Sensors in Remote Sensing.”</span> <a href="https://gisgeography.com/passive-active-sensors-remote-sensing/">https://gisgeography.com/passive-active-sensors-remote-sensing/</a>.
</div>
<div id="ref-he2019" class="csl-entry" role="doc-biblioentry">
He, Yuanrong, Weiwei Ma, Zelong Ma, Wenjie Fu, Chihcheng Chen, Cheng-Fu Yang, and Zhen Liu. 2019. <span>“Using Unmanned Aerial Vehicle Remote Sensing and a Monitoring Information System to Enhance the Management of Unauthorized Structures.”</span> <em>Applied Sciences</em> 9 (22): 4954. <a href="https://doi.org/10.3390/app9224954">https://doi.org/10.3390/app9224954</a>.
</div>
<div id="ref-hemati2021" class="csl-entry" role="doc-biblioentry">
Hemati, MohammadAli, Mahdi Hasanlou, Masoud Mahdianpari, and Fariba Mohammadimanesh. 2021. <span>“A Systematic Review of Landsat Data for Change Detection Applications: 50 Years of Monitoring the Earth.”</span> <em>Remote Sensing</em> 13 (15): 2869. <a href="https://doi.org/10.3390/rs13152869">https://doi.org/10.3390/rs13152869</a>.
</div>
<div id="ref-jensen2015" class="csl-entry" role="doc-biblioentry">
Jensen, John R. 2015. <em>Introductory Digital Image Processing: A Remote Sensing Perspective</em>. Old Tappan: Pearson Education.
</div>
<div id="ref-llorens2021" class="csl-entry" role="doc-biblioentry">
Llorens, Rafael, José Antonio Sobrino, Cristina Fernández, José M. Fernández-Alonso, and José Antonio Vega. 2021. <span>“A Methodology to Estimate Forest Fires Burned Areas and Burn Severity Degrees Using Sentinel-2 Data. Application to the October 2017 Fires in the Iberian Peninsula.”</span> <em>International Journal of Applied Earth Observation and Geoinformation</em> 95 (March): 102243. <a href="https://doi.org/10.1016/j.jag.2020.102243">https://doi.org/10.1016/j.jag.2020.102243</a>.
</div>
<div id="ref-potapov2020" class="csl-entry" role="doc-biblioentry">
Potapov, Peter, Matthew C. Hansen, Indrani Kommareddy, Anil Kommareddy, Svetlana Turubanova, Amy Pickens, Bernard Adusei, Alexandra Tyukavina, and Qing Ying. 2020. <span>“Landsat Analysis Ready Data for Global Land Cover and Land Cover Change Mapping.”</span> <em>Remote Sensing</em> 12 (3): 426. <a href="https://doi.org/10.3390/rs12030426">https://doi.org/10.3390/rs12030426</a>.
</div>
<div id="ref-ramos2020" class="csl-entry" role="doc-biblioentry">
Ramos, Tiago B., Nádia Castanheira, Ana R. Oliveira, Ana Marta Paz, Hanaa Darouich, Lucian Simionesei, Mohammad Farzamian, and Maria C. Gonçalves. 2020. <span>“Soil Salinity Assessment Using Vegetation Indices Derived from Sentinel-2 Multispectral Data. Application to Lezíria Grande, Portugal.”</span> <em>Agricultural Water Management</em> 241 (November): 106387. <a href="https://doi.org/10.1016/j.agwat.2020.106387">https://doi.org/10.1016/j.agwat.2020.106387</a>.
</div>
<div id="ref-segarra2020" class="csl-entry" role="doc-biblioentry">
Segarra, Joel, Maria Luisa Buchaillot, Jose Luis Araus, and Shawn C. Kefauver. 2020. <span>“Remote Sensing for Precision Agriculture: Sentinel-2 Improved Features and Applications.”</span> <em>Agronomy</em> 10 (5): 641. <a href="https://doi.org/10.3390/agronomy10050641">https://doi.org/10.3390/agronomy10050641</a>.
</div>
<div id="ref-surdu2014" class="csl-entry" role="doc-biblioentry">
Surdu, C. M., C. R. Duguay, L. C. Brown, and D. Fernández Prieto. 2014. <span>“Response of Ice Cover on Shallow Lakes of the North Slope of Alaska to Contemporary Climate Conditions (1950<span></span>2011): Radar Remote-Sensing and Numerical Modeling Data Analysis.”</span> <em>The Cryosphere</em> 8 (1): 167–80. <a href="https://doi.org/10.5194/tc-8-167-2014">https://doi.org/10.5194/tc-8-167-2014</a>.
</div>
<div id="ref-zhang2019" class="csl-entry" role="doc-biblioentry">
Zhang, Jingcheng, Yanbo Huang, Ruiliang Pu, Pablo Gonzalez-Moreno, Lin Yuan, Kaihua Wu, and Wenjiang Huang. 2019. <span>“Monitoring Plant Diseases and Pests Through Remote Sensing Technology: A Review.”</span> <em>Computers and Electronics in Agriculture</em> 165 (October): 104943. <a href="https://doi.org/10.1016/j.compag.2019.104943">https://doi.org/10.1016/j.compag.2019.104943</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Introduction</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Week2.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Week 2 Portfolio</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>