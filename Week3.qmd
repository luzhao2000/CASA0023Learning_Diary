# Week 3 Corrections

In this week, we learnt how to pre-process remote sensing imagery based on four types of corrections, feathering, and image enhancement. This part is very important because if the pre-processing is not done well, it may affect the subsequent analysis and the accuracy of the final results.

## Summary

Summary part of the learning diary in this week including two sections, one is summary for lecture, the other is summary for practical.

### Summary for lecture

Different sensors may have different ways of taking images, some are similar to push broom (Fig.1), such as SPOT and Quickbird, while sensors like Landsat satellites collect data like whisk broom (Fig.1), in which case the scan line corrector (SLC) is important to control and correct the course and direction of the scan line. Since Landsat 7 did not add SLC, there are gaps between the collected data (Fig.2) and it is difficult to fill in the missing data.

![Fig.1 principle of push broom and whisk broom sensor. Source: @indiawaterportal2012](week3_sensor.png){width="300"}

![Fig.2 Scan line with and without the scan line corrector. Source: @landsatmissions](week3_slc.png){width="300"}

#### Part1: imagery corrections

Depending on the quality of the acquired data and the needs of the user, the collected raw data is usually first corrected, which includes geometric correction, atmospheric correction, topological correction and radiometric calibration.

-   Geometric correction

We need to do geometric correction is because the following four conditions may occur during the data collection process to cause image distortions. First is the capture of images due to the difference in view angles may cause the shadow of the objects on the image or the shadow of the aircraft sensors. Secondly, it is influenced by the topography, for example, the mountain is not a flat surface but has to be "printed" on a two-dimensional image. Thirdly, affected by weather, such as winds, heavy rain and other bad weather, sensors such as those carried by airplanes and balloons are unable to collect data stably, which can also cause image distortion. Last but not least, it is also possible that the rotation of the Earth makes the adjacent images misaligned and not perfectly aligned.

The principle of geometric correction is to determine some ground control points (GCP) with coordinates after selecting the target image (uncorrected image) and the reference image (corrected image), which means that we need to collect GPS data as well. In addition, to establish a function (e.g linear, polynomial, projective, etc.) based on the mathematical relationship between the positions of these GCPs in the uncorrected image and corrected image. The complete image is corrected according to this function, and the geometrically corrected image is obtained. Following Figure 3 is an example for comparing the difference between the same image before and after geometric correction.

![Fig.3 Comparison between the same image before and after geometric correction. Source: @xue2021](week3_geometric_cor.png){width="400"}

Notice:

1.  It is also needed to minimize the RMSE value, usually less than 0.5. Add more GCPs might decrease the RMSE.
2.  The points after rectified may not fall on the grid squares, and even some might fall outside the boundary. To solve this problem, we can do re-sample based on suitable methods to let the pixels in the output grids have normal values.

-   Atmospheric correction

According to @jensen2015, atmospheric scattering and topographic attenuation are the most two important sources of environment attenuation. We perform atmospheric correction to reduce the effect of clouds on the image and reduce the contrast of the image. For example, since clouds are very bright, they would cause an adjacency effect that makes the surrounding pixels brighter than they really are. There are two types of atmospheric correction, one is relative atmospheric correction, the other is absolute atmospheric correction. Absolute atmospheric correction (e.g. FLAASH, empirical line correction) is changing digital brightness values into scaled surface reflectance, which can use atmospheric radiative transfer models, but it would be really hard, since it needs a lot of data and a long-time period to do this.

Dark object subtraction (DOS) and Psuedo-invariant Features (PIFs) are two relative atmospheric correction methods. Dark object subtraction (DOS) is based on the assumption that the reflectance of dark objects in images (e.g., bodies of water, shadows of mountains, etc.) has almost no reflectance in some specific wavelength bands, and therefore the reflectance corresponding to these dark objects in the image should be a fraction of the energy absorbed by the sensor after the solar radiation is directly reflected by the atmosphere [@blamannen2011]. Therefore, by subtracting the value corresponding to the darkest object pixel in the image, a higher contrast image that is closer to the real situation is obtained. While PIFs are matching the brightness pixels in the remote sensing images and the spectral reflectance data measured simultaneously using a field spectrometer in the linear relationship, and use linear regression to adjust (predict) the values of other pixels in the image to be corrected.

However, it is not always necessary to do atmospheric correction, such as when classifying a single image, independent classification of multiple date imagery, and other situation [@jensen2015].

-   Topological (orthorectification) correction

The essence of topological correction is to computationally adjust the image looks same as the view at nadir look and remove distortions, which requires sensor geometry and an elevation model. Topological correction can be done by using software like QGIS and SAGA GIS, or R as well.

Notice: Atmospheric correction should be done before topological correction.

-   Radiometric calibration

Radiometric calibration is based on the raw data collected from the satellites to change digital numbers (DN) into spectral radiance, which means that change image brightness into the amount of light within a band from a sensor in the field of view (FOV). After the transmission, the spectral radiance is with units and meaning.

Notice:

1.  DNs do not have units.
2.  Radiance is usually called top of atmosphere radiance.
3.  Level 2 product refers to the data has been changed or advanced.

#### Part2: data joining and enhancement

Data joining is like merging imagery together. In many cases, we need to join data sets to generate a complete remote sensing image covering the whole study area when the study area is relatively large or located at the junction of multiple images. In the process of joining, the average of the pixel values of the overlapping parts is usually chosen as the pixel value of the joined images. The reason for doing so is to reduce the difference of DN values between the two images.

Image enhancement refers to the enhancement of image contrast because many different materials may have little difference in their ability to reflect the same wavelength of energy, which may cause the range of DNs of the raw image to be concentrated in a smaller range, resulting in a lack of significant contrast and the need for contrast enhancement. Common methods include expand the range of DNs from Minimum to Maximum, percentage linear and standard deviation, and piecewise linear contrast stretch. In addition, there are many other enhancement which can be applied to improve the quality and visual apperance of the imagery, including ratio enhancement, filtering (e.g. edge enhancement), PCAtexture enhancement, pan sharpen and data fusion (decision level fusion, object-level fusion, image fusion and satellites data fusion).

Notice: Image stretch only change how the image express by stretching the range of original image in a more suitable range, it does not change the raw image.

### Summary for practical

Notice:

1.  Formula of DOS, and the meanings of these indices in the formula

### Questions

1.  How many GCPs do we need to select when doing geometric correction?
2.  Why atmospheric correction is not always necessaryly done?
3.  What is the difference between empirical line correction and PIFs, both of them correct image based on regression model?
4.  How to convert TOA radiance to TOA reflectance?
5.  What is the light source when mention TOA reflectance and surface reflectance?
6.  Is pan sharpen a kind of high pass enhancement? if not, what is the difference between them?
7.  Why color of pixels outside the overlapping area of the following images also changed after joining?

![Fig.4 Comparison between two images before and after joining.](week3_join_data.png){width="600"}

## Application

## Reflection
