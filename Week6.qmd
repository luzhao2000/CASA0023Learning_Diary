# Week6 Classification

In this week, we focus on classification. We reviewed why we need to classify data in some research and how to use the classified data, and we learnt nature of several remote sensing classification methods. Based on the classification content that we learnt from lecture and relevant literature, I collect several applications based on different classification methods and compare the differences between them.

## Summary

The summary part of learning diary in this week has been divided by three parts, including how the classified data has been used in the previous research and real life, summary of classification methods, and summary of practical.

### Utilization of classified data

-   Air pollution and land use and land cover

Imagery after classified can be used to monitor air pollution during a certain period. For example, based on Sentinel-3 imagery to collect and monitor sea and land surface temperature, and collect other data to analyze the potential factors affect the sea and land surface temperature. According to the classification results and relevant statistic graphs, it is clear to identify the changes of temperature between each time during the research period.

-   Land use and land cover (urban green spaces)

Imagery collected by different sensors can be used for different procedures or analysis when analyzing issue related to urban green space. For example, we can choose medium spatial resolution imagery for decision making and modelling. Moreover, we can combine different sensors for urban garden mapping, counting urban trees, which will combine their strengths and optimize the results.

-   Monitoring deforestation and illegal logging

-   Forest fire hazard mapping

Expert systems is a system that answer the non-expert users' queries based on the basic knowledge from an expert and give suitable advice back to the users. As machine learning, experts set training samples and test data to build a model for classification or prediction and give the classification or regression results back to users based on the data that users input.

Commonly, we use classification and regression trees (CART), random forest, and other machine learning methods to classify imagery. When creating a decision tree (classification tree), we need to set a root and few decisions to split data into two sets. This process is not random, we need to modify the model with the lowest Gini impurity for each splitting time.

For building regression trees, we set the root of th regression tree and divide data based on sum of squared residuals, which we hope the value of SSR is the lowest within a certain neighborhood. In addition, we need to split data into training and testing data for each validation to avoid overfitting. To avoid overfitting, we can calculate Tree Score:

Tree Score = SSR + tree penalty(alpha) \* T(number of leaves)

Since we start with an ideal model, so that the start value of alpha is 0. Therefore, at the beginning, we will get the lowest tree score. Then, we need to divide data into training and testing data set several times (probably 10 times), build the model, and delete leaves to check whether the tree score and SSR change, until we get the lowest SSR expect for the tree score at the beginning, and return the corresponding alpha value to calculate tree score, and finish the modelling process.

::: callout-note
1.  Gini impurity = 1 - (probability of true)^2^ - (probability of false)^2^
2.  The best sum of SSR value across all variables can be the root of regression tree
3.  20 pixels (or other units) is often the minimum number of pixels in a leaf
4.  Decision tree are not great for predicting with new data
:::

Random forests, growing many classification decision tree, might solve the disadvantage of decision tree. Since random forest can be considered as the combination of many decision trees, so that the process of make final decision based on random forest is bootstrapping the complete data set into many data set, and each one will be divided for training and testing. Build decision trees based on different training and testing data sets and aggregate the results of the ensemble of trees.

::: callout-note
1.  Number of variables per tree is the square root of variables in the original data.
2.  There might be out of bag error, which caused by all trees that did not have the rows in the original data and average prediction error.
:::

### Remote sensing data classification methods

Image classification is to turn pixels into different pre-defined categorical classes. There are two general types of classification based on pixels, including unsupervised classification, supervised classification.

### Summary of practical

This week's practical is mainly used to familiarize with the common remote sensing data classification methods in GEE. The main workflow of practical in this week shows in the following Figure 1. Our main project in this week includes Sentinel data pre-processing and classification based on the study area of Shenzhen, China.

![Fig.1 Workflow of practical in Week 6](week6_practical_summary.jpg){fig-align="center" width="600"}

After loading Sentinel-2 imagery and the Shenzhen boundary polygon, we found that there are clouds that cover the objects in several images that we collected based on the location, sensor, collecting period. Therefore, we have two methods to solve this question. One method is filter data again, based n the cloud level to filter images satisfy the condition of low cloud level, which means that the cloudy pixel percentages of each image should be lower than 1%. Figure 2 shows the result of dealing with clouds based on the first method. In Figure 2, the clouds are barely visible as an obstruction to the image.

![Fig.2 Imagery after dealing with the cloud issue by using the first method](week6_practical_cloudway1.png){width="400"}

The other method is to mask the cloudy pixels and do division to decrease the impact of clouds on the subsequent processes and analyses. However, based on the imagery collected in this project, the second method did not work well. The clouds can still be seen clearly in Figure 3 below.

![Fig.3 Imagery after dealing with the cloud issue by using the second method](week6_practical_cloudway2.png){width="400"}

To avoid the influence of clouds on the subsequent classification, I chose to take median value of each pixel from all images that I collected as the image which will be used to do classification later. The relevant code shows in the following code chunk:

``` javascript
var way_two_median = waytwo.reduce(ee.Reducer.median());
var vis_params = {
  bands: ['B4_median', 'B3_median', 'B2_median'],
  min: 0.0,
  max: 0.3,
};
Map.addLayer(way_two_median, vis_params, 'True Color (432)');
```

After clip the image based on the boundary of Shenzhen, I got the acceptable image without cloud issue within the boundary of Shenzhen, China (Figure 4). Then, we can move to do classification.

![Fig.4 Image will be used for classification without cloud issue](week6_practical_imagebeforeclassification.png){width="400"}

There are three different classification methods used in this practical, including CART classification decision tree (Figure 5), random forest based on splitting polygons (Figure 6), and random forest based on splitting pixels (Figure 7). I create several polygons for 5 types of land use and land cover for training the models, including urban, water, grass, forest, and bare earth. The type of land use represented by the different colors can be distinguished according to the inspector. Light pink is urban, purple is water, light green is bare earth, dark pink is grass, and dark green is forest. The same color represents the same type of feature in all three classifications. Code used in GEE for do classification based on CART shows in the code chunk:

``` javascript
var classifier = ee.Classifier.smileCart().train({
  features: training,
  classProperty: classProperty,
}); //build CART classifier based on the selected polygons and classes
print('CART, explained', classifier.explain());
var classified = waytwomedian_clip.classify(classifier); //apply the classifer
Map.centerObject(shenzhen);
Map.addLayer(classified, {min: 1, max: 5, palette: ['d99282', '466b9f', 'ab0000', 'dfdfc2', 'b3ac9f', '1c5f2c']}, "classified"); // output classification result
```

Moreover, after comparing with the original image, I found that the result of this CART classification is not very accurate, for example, some parts of the water area with greenish color is classified as grass type. But the division between forest and urban is relatively accurate.

![Fig.5 Classification result based on CART classification decision tree](week6_practical_CART_classified.png){width="600"}

Based on the visual comparison of the original remote sensing images and the classification results in Figure 6, although no valid accuracy was obtained, it can be seen that the classification results by using random forest based on splitting polygons are relatively more accurate compared to the CART classification results. The lack of valid accuracy may be due to the fact that training and testing data sets were divided into polygons, so that there are not enough polygons.

![Fig.6 Classification result by random forest based on splitting polygons](week6_practical_randomforest_classified_polygon.png){width="600"}

The difference between two random forest classification methods used in this practical is when I did random forest classification based on splitting pixels, it is needed to transform polygons that I created into pixels with corresponding class:

``` javascript
var pixel_number= 1000;
var urban_points=ee.FeatureCollection.randomPoints(urban, pixel_number).map(function(i){
  return i.set({'class': 1})})
var water_points=ee.FeatureCollection.randomPoints(water, pixel_number).map(function(i){
  return i.set({'class': 2})})
var grass_points=ee.FeatureCollection.randomPoints(grass, pixel_number).map(function(i){
  return i.set({'class': 3})})
var bare_earth_points=ee.FeatureCollection.randomPoints(bare_earth, pixel_number).map(function(i){
  return i.set({'class': 4})})
var forest_points=ee.FeatureCollection.randomPoints(forest, pixel_number).map(function(i){
  return i.set({'class': 5})})
```

From Figure 7 below, we can visualize the validation error matrix, validation overall accuracy, and validation customer accuracy, and the accuracy of the latter two is very high, indicating that the model built based on splitting-pixel random forest is very accurate in classification.

![Fig.7 Classification result by random forest based on splitting pixel with overall accuracy and customer accuracy](week6_practical_randomforest_classified_pixel.png){width="600"}

Therefore, based on the above three classification results, it may be more appropriate for this practical to use random forest based on splitting pixels to classify the acquired Sentinel-2 images in the range of Shenzhen.

### Questions

1.  The proportion of training and testing data set might be different from DS course?
2.  Will data leakage happen when doing CART classification by using training data to generate classifier to classify the whole image?
3.  Why we need QA and why we set "qa60"?
4.  Why the scale = 10 when doing random forest in GEE? What is the meaning of scale =10 here?

## Application

-   Application of CART classification

-   Application of random forest classification

-   Application of other classification methods

## Reflection

-   what you have learnt?

-   what was interesting?

-   why an why might the data or tools presented this week be useful in the future to you, or not useful but something similar might be?
